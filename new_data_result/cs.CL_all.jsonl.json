{
  "A Survey of Large Language Models for Arabic Language and its Dialects": {
    "主题": "阿拉伯语大语言模型",
    "场景": "针对阿拉伯语及其方言的大语言模型设计与应用",
    "创新点": [
      "系统梳理阿拉伯语大语言模型的架构和数据集特点（涵盖古典阿拉伯语、现代标准阿拉伯语和方言）。",
      "评估模型的开放性（源代码、训练数据、模型权重等），强调研究可重复性和透明度的重要性。"
    ]
  },
  "Fast Best-of-N Decoding via Speculative Rejection": {
    "主题": "LLM推理时对齐优化",
    "场景": "大型语言模型（LLM）生成符合人类偏好响应时的计算效率提升",
    "创新点": [
      "提出**推测性拒绝（Speculative Rejection）算法**，在推理时实现高效对齐，无需训练阶段权重调整",
      "计算效率比传统Best-of-N方法提升16-32倍，同时保持奖励模型的高响应得分"
    ]
  },
  "Improving Model Evaluation using SMART Filtering of Benchmark Datasets": {
    "主题": "NLP模型评估优化",
    "场景": "通过筛选基准数据集提升模型评估的准确性和效率",
    "创新点": [
      "提出SMART过滤方法，通过移除易样本、数据污染样本和嵌入空间相似的样本，提高数据质量",
      "在小规模精选数据集上保持模型排名一致性的同时，平均减少48%数据集大小，提升评估效率"
    ]
  },
  "The Curious Case of the Single-Use \"Library\"": {
    "主题": "大型语言模型（LLMs）中的库学习系统",
    "场景": "数学推理任务中的工具库重用性研究",
    "创新点": [
      "通过对LEGO-Prover和TroVE两个库学习系统的研究，揭示了工具复用在数学任务中极其罕见的现象",
      "实验表明性能提升主要来自自我纠正（self-correction）和自我一致性（self-consistency），而非工具复用"
    ]
  },
  "A Task for Summarizing Equation   Dependencies in STEM Manuscripts": {
    "主题": "数学方程依赖关系分析",
    "场景": "STEM文章中的数学表达式依赖关系提取和总结",
    "创新点": [
      "引入“推导图”新概念，总结STEM文章的数学内容",
      "首次全面评估分析和NLP模型在提取方程依赖关系上的性能（F1分数40-50%）",
      "揭示NLP模型在数学文本理解上未显著优于传统分析方法的现状"
    ]
  },
  "Ambiguity is the last thing you need": {
    "主题": "法律语言消除歧义",
    "场景": "合同法律文件中的语言歧义引发争议和诉讼",
    "创新点": [
      "提出在合同制定中优先使用明确无歧义的语言以减少争议",
      "强调法律对弱势方（如消费者）的明文保护需依赖清晰表述",
      "指出英语同义词过多是歧义根源，需系统性优化法律文本措辞"
    ]
  },
  "Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed   Intent Discovery": {
    "主题": "意图发现",
    "场景": "面向任务的对话系统，用于在已知意图之外发现新意图",
    "创新点": [
      "提出伪标签增强的原型对比学习（PLPCL）模型，通过迭代利用伪标签探索正/负样本，弥合表示学习与聚类间的差距",
      "设计融合已知意图与待发现意图监督信号的原型学习方法，提升知识迁移效果",
      "首次统一处理开放意图发现和跨领域（OOD）意图发现两种场景"
    ]
  },
  "Strategic Planning of Problem-solving Trajectories for   Zero-Shot In-Context Learning": {
    "主题": "零样本上下文学习",
    "场景": "多任务环境中的问题解决轨迹规划",
    "创新点": [
      "将零样本上下文学习重构为规划问题，提出基于蒙特卡洛树搜索的轨迹规划方法（DAWN-ICL）",
      "设计新型演示感知的Q值函数，优化搜索效率并提升伪演示生成可靠性"
    ]
  },
  "Ethical Focus   and Bias Detection through Role-Play": {
    "主题": "LLM伦理风险评估与偏见检测",
    "场景": "评估主流大语言模型在伦理决策中的风险态度与系统性偏见",
    "创新点": [
      "提出新型伦理决策风险态度量表（EDRAS），将认知科学中的DOSPERT量表创新应用于LLM评估",
      "结合风险量表和角色扮演方法，首次实现LLM系统性偏见的定量化评估",
      "通过跨领域评估揭示LLM的\"风险人格\"特征，重点关注伦理领域的群体偏见量化"
    ]
  },
  "Where   this contribution lies?": {
    "主题": "生成语言学在人工智能中的贡献",
    "场景": "探讨生成语言学（GL）对人工智能（AI）的理论和技术影响，以及语言学在科学与人文学科中的定位争议。",
    "创新点": [
      "系统论证生成语言学（尤其是乔姆斯基学派）的理论（如普遍语法、句法计算系统）对AI核心技术（如大语言模型、编程语言设计）的底层贡献",
      "通过跨学科证据（神经科学、语言习得、Python语言设计）量化GL对AI的实际影响，突破传统人文学科的定性争论",
      "提出GL与AI在语言输入本质上的分歧点，为两者进一步融合提供研究方向"
    ]
  },
  "Transformers Determine Top Tokens In Order": {
    "主题": "Transformer模型内部机制分析",
    "场景": "语言、视觉和语音模型中的top-k标记预测",
    "创新点": [
      "揭示Transformer模型按顺序确定top-k标记的机制，即依次从高到低固定标记排名",
      "提出任务转换机制解释这一现象，并证明可通过隐藏层嵌入预测当前任务",
      "提出新型标记级早期退出策略，在性能与效率平衡上优于现有方法"
    ]
  },
  "Reasoning or a Semblance of it? A Diagnostic Study of Transitive   Reasoning in LLMs": {
    "主题": "大型语言模型的传递推理能力诊断",
    "场景": "评估LLaMA 2和Flan-T5在QASC和Bamboogle数据集上的真实逻辑推理能力",
    "创新点": [
      "通过控制变量（如词重叠、预训练知识和命名实体）首次系统分析LLMs传递推理的依赖机制",
      "发现Flan-T5相比LLaMA 2对知识干扰更具鲁棒性，揭示微调数据对逻辑理解的关键作用"
    ]
  },
  "LLMs Can Evolve Continually on Modality for X-Modal Reasoning": {
    "主题": "多模态大语言模型持续学习",
    "场景": "多模态理解中的模态扩展与推理",
    "创新点": [
      "提出PathWeave框架，支持模态路径切换与扩展，无需联合模态预训练即可扩展新模态",
      "引入Adapter-in-Adapter结构，实现单模态与跨模态适配器的无缝集成",
      "基于MoE的门控模块增强多模态交互，减少98.73%的参数训练负担"
    ]
  },
  "A Stack-Propagation Framework for Low-Resource Personalized Dialogue   Generation": {
    "主题": "低资源个性化对话生成",
    "场景": "开放领域对话系统，在训练数据稀缺的情况下生成符合用户个性的自然回复",
    "创新点": [
      "提出堆叠传播框架，将一致性理解作为回复生成的 regularization（正则化）",
      "采用双解码器架构：首个解码器生成回复，次解码器作为正则化器联合建模回复生成与一致性理解",
      "在低资源条件下显著降低对密集个性化数据的依赖，同时保持性能竞争力"
    ]
  },
  "Sentiment Analysis on News": {
    "主题": "通胀预测中的情感分析",
    "场景": "结合大型语言模型（LLMs）与经典通胀临近预测框架，用于高波动时期（如COVID-19疫情）的实时通胀监测。",
    "创新点": [
      "提出InflaBERT模型：基于BERT的LLM，专门微调用于分析通胀相关的新闻情感，生成月度新闻情感指数（NEWS）。",
      "改进传统经济模型：将情感指数融入仅依赖宏观经济自回归过程的克利夫兰联储模型，在疫情期间显著提升临近预测准确度。",
      "方法论突破：首次验证情感分析与传统经济指标结合的潜力，为实时通胀监测提供新方向。"
    ]
  },
  "Unified Instruction-aware Heterogeneous Knowledge Retrievers": {
    "主题": "异构知识检索",
    "场景": "现实世界中异构和多样化知识源的检索任务",
    "创新点": [
      "构建统一检索空间处理异构知识，支持多样化用户指令",
      "提出三阶段训练框架（自监督预训练、文本锚定嵌入对齐、指令感知微调）",
      "首次发布原生异构知识检索基准CompMix-IR（含9400 QA对/千万级语料）"
    ]
  },
  "A Compact Survey": {
    "主题": "因果抽象与模型可解释性",
    "场景": "复杂AI模型（如深度学习系统）的决策过程解释",
    "创新点": [
      "提出因果抽象作为解释AI模型行为的理论框架",
      "探讨其理论基础与实际应用对模型可解释性领域的影响"
    ]
  },
  "Retrieval Augmented Retrieval with In-Context Examples": {
    "主题": "检索增强的嵌入模型优化",
    "场景": "开放域检索任务（如BeIR、RAR-b数据集）中的查询性能提升",
    "创新点": [
      "提出RARe方法，通过微调预训练模型，利用与目标查询语义相似的上下文示例（query-document对）优化检索性能",
      "适配多种基础架构（如仅解码器语言模型、检索器模型），跨数据集实现最高+2.72% nDCG提升",
      "首次验证上下文示例机制在嵌入模型中与LLMs类似的强领域外泛化能力"
    ]
  },
  "Personality Analysis from Online Short Video Platforms with Multi-domain   Adaptation": {
    "主题": "多模态人格分析",
    "场景": "基于在线短视频平台的人格分析，应用于个性化推荐、情感分析与人机交互",
    "创新点": [
      "提出基于时间戳的多模态对齐机制，同步不同模态数据以提升特征整合准确性",
      "结合双向LSTM与自注意力机制建模时序依赖与跨模态交互关系",
      "开发基于梯度的多源域适应方法，解决目标域标注数据稀缺下的模型泛化问题"
    ]
  },
  "User-Aware Multilingual Abusive Content Detection in Social Media": {
    "主题": "多语言滥用内容检测",
    "场景": "社交媒体中低资源印度语言的有害评论识别",
    "创新点": [
      "提出双模块结构，分别学习社交上下文和文本上下文特征以提升检测精度",
      "整合用户历史和行为特征，增强低资源语言环境下模型性能",
      "在150万+评论数据集上验证，F1值比现有方法最高提升9.52%"
    ]
  },
  "Predicting Punishment   Durations in Indonesian Court Rulings": {
    "主题": "法律判决预测模型",
    "场景": "印度尼西亚法院判决刑期预测",
    "创新点": [
      "提出CNN+BiLSTM混合模型结合注意力机制，有效捕捉法律文本的局部模式和长期依赖关系",
      "采用改进的文本归一化流程，显著提升模型对拼写错误和合并错误等常见问题的处理能力",
      "发现仅使用前30%高频词的关键策略，平衡信息保留与计算效率"
    ]
  },
  "Multi-Field Adaptive Retrieval": {
    "主题": "多字段自适应检索",
    "场景": "针对结构化文档（如含标题、正文、HTML标题等字段）的搜索和检索增强生成任务",
    "创新点": [
      "提出灵活的多字段索引框架（MFAR），支持对任意数量和类型的结构化文档字段分别进行密集检索和词法检索",
      "开发动态权重预测模型，根据查询条件自适应地学习各字段重要性，实现实时最优字段组合加权",
      "首次在结构化数据检索中实现密集表征与词法表征的跨字段优化，显著提升文档排序效果"
    ]
  },
  "Introducing Inductive Bias via   Representational Alignment": {
    "主题": "神经网络架构优化",
    "场景": "解决传统网络架构在特定任务中性能不佳的问题（如过拟合、欠拟合）",
    "创新点": [
      "提出“引导网络”（guide network）方法，通过表征对齐传递归纳偏置，提升目标网络的性能",
      "利用未经训练的引导网络传递部分架构先验，改善目标网络的初始化效果",
      "为研究架构先验提供数学工具，并潜在实现自动化架构设计"
    ]
  },
  "Architectural Flaw Detection in Civil Engineering Using GPT-4": {
    "主题": "AI在建筑缺陷检测中的应用",
    "场景": "土木工程设计阶段的建筑缺陷检测（如缺失门窗、承重问题等）",
    "创新点": [
      "首次将GPT-4 Turbo视觉模型用于建筑设计缺陷检测，实现高精度识别（通过准确率、召回率等指标验证）",
      "扩展AI检测能力至多维度问题（材料缺陷、建筑规范合规性等），超越传统人工检查范围",
      "提出AI驱动设计优化的闭环框架，降低后期修改成本并提升可持续性"
    ]
  },
  "A Learnable Framework for Interpreting Nonlinear Neural   Encoding Models": {
    "主题": "非线性神经编码模型解释框架",
    "场景": "神经网络表征与脑神经响应的非线性映射分析，应用于视觉编码预测fMRI记录的大脑活动",
    "创新点": [
      "提出LinBridge框架，通过雅可比矩阵分解非线性映射为线性固有成分和样本选择性非线性偏置",
      "采用自监督学习策略，从测试集雅可比矩阵中自适应提取线性与非线性成分",
      "揭示视觉处理层级中非线性分布的变异性，提供视觉皮层分层非线性特征的新证据"
    ]
  },
  "Effective Strategies for Mitigating Hallucinations   in Large Language Models for Data Analytics": {
    "主题": "大型语言模型幻觉缓解策略",
    "场景": "数据分析中的自然语言查询",
    "创新点": [
      "提出四种针对性策略（结构化输出生成、严格规则执行、系统提示增强、语义层集成），相比传统微调更有效",
      "证明这些策略能提高数据分析中LLM查询的准确性，增强可靠性"
    ]
  },
  "Decomposing Materials Discovery by Mimicking Human Experts": {
    "主题": "基于LLMs的材料发现框架",
    "场景": "加速固态材料的设计与发现",
    "创新点": [
      "提出三阶段模仿人类专家工作流程（检索-转换-生成）的MatExpert框架",
      "结合对比学习与LLMs提升生成材料的有效性/分布性/稳定性",
      "+ 首次实现语言生成模型驱动的全流程计算材料设计系统"
    ]
  },
  "Attacks against Abstractive Text Summarization Models through Lead Bias   and Influence Functions": {
    "主题": "文本摘要模型对抗攻击",
    "场景": "针对抽象文本摘要模型的对抗性扰动与数据投毒攻击",
    "创新点": [
      "利用摘要模型固有的首句偏好（lead bias）进行对抗扰动",
      "首次应用影响函数（influence functions）实施数据投毒攻击",
      "揭示被攻击模型行为变化（从抽象摘要转向抽取式摘要）"
    ]
  },
  "Think Carefully and Check Again! Meta-Generation Unlocking LLMs for   Low-Resource Cross-Lingual Summarization": {
    "主题": "低资源跨语言摘要生成",
    "场景": "利用大型语言模型（LLMs）解决低资源语言的跨语言摘要任务",
    "创新点": [
      "提出四步零样本方法（SITR）：摘要生成、改进、翻译和精炼，有效解锁LLMs在低资源语言跨语言摘要中的潜力",
      "设计相应提示模板，显著提升GPT-3.5和GPT-4在低资源语言跨语言摘要任务中的性能"
    ]
  },
  "Dynamic layer selection in decoder-only transformers": {
    "主题": "动态推理优化",
    "场景": "大型语言模型（LLM）的自然语言生成（NLG）推理效率优化",
    "创新点": [
      "提出**层跳过（layer skipping）**比早期退出（early exit）对预训练解码器模型更鲁棒",
      "揭示基于隐藏状态信息进行逐令牌计算适配的困难",
      "通过构建预言控制器，证明**按序列动态分配计算**可显著提升效率（仅需23.3%层数保持同等性能）"
    ]
  },
  "Vulnerability of LLMs to Vertically Aligned Text Manipulations": {
    "主题": "LLMs垂直文本输入漏洞",
    "场景": "数学计算、填字游戏等需处理垂直文本的现实应用",
    "创新点": [
      "揭示解码器型LLMs在垂直文本分类任务中存在显著准确性下降",
      "验证链式思考（CoT）无法缓解该漏洞，但少量样本学习可改善",
      "通过分析分词机制和注意力矩阵探究漏洞根源"
    ]
  },
  "Agentic Reinforcement Learning for Real-World Code Repair": {
    "主题": "代码修复的强化学习",
    "场景": "真实代码仓库中的复杂构建和依赖问题修复",
    "创新点": [
      "开发可验证的代码修复流程，通过固定依赖和禁用自动升级提升重现性",
      "提出可扩展的简化流程以支持大规模强化学习训练",
      "结合监督微调和强化学习训练代码修复模型，其中SFT模型性能相当但体积缩小56倍"
    ]
  },
  "Preference Learning   Fails, Supervision Succeeds": {
    "主题": "LLM性别偏见控制技术",
    "场景": "针对LLM在职业中性语境中产生性别偏见语言的场景，评估六种控制技术的效果。",
    "创新点": [
      "首次系统比较六种偏见控制方法（包括监督微调、偏好优化等），揭示监督微调（SFT）在合规性和多样性上的显著优势",
      "发现偏好学习（如DPO）无法满足组合约束的逻辑结构，提出显式正向监督对解决组合偏见的必要性",
      "量化控制强度与生成自然度的权衡，证明Ctrl-G方法虽能完全合规但严重牺牲流畅性"
    ]
  },
  "Automated Discovery of Narrative-Based Jailbreaks for   Large Language Models": {
    "主题": "LLM漏洞自动挖掘",
    "场景": "AI安全领域，用于检测大语言模型（如GPT-4、Llama-3等）在网络安全应用中的对抗性攻击弱点",
    "创新点": [
      "提出Jailbreak Mimicry方法，通过参数高效微调（LoRA）训练小型攻击模型，实现单次自动生成叙事式越狱提示",
      "将对抗性提示发现从手工设计转化为可复现的科学流程，攻击成功率提升54倍（ASR 81% vs 1.5%）",
      "揭示技术领域（网络安全93% ASR）和欺骗类攻击（欺诈87.8% ASR）的特别脆弱性，为AI安全防御提供针对性方向",
      "开发自动化危害评估框架（结合Claude Sonnet 4与人工验证），实现网络安全红队测试的可扩展评估"
    ]
  },
  "Understanding and Characterizing the Emotional   Latent Space of Large Language Models": {
    "主题": "大型语言模型的情感表征分析",
    "场景": "探究LLMs内部如何表示和处理情感，覆盖五语言的八种情感数据集",
    "创新点": [
      "识别出低维情感流形，揭示情感表征的方向性编码和跨层分布特性",
      "提出可学习干预模块，实现语义保留下的情感操控，尤其对基础情绪的跨语言控制"
    ]
  },
  "A Benchmark for Open-Domain Numerical Fact-Checking Enhanced by Claim   Decomposition": {
    "主题": "开放领域数值事实核查",
    "场景": "自动化验证自然语言中的数值声明，模拟人类事实核查员的检索与推理过程",
    "创新点": [
      "提出QuanTemp++数据集，包含自然数值声明及相关证据，通过声明分解模拟人类核查流程，避免时间泄漏问题",
      "采用近似人类核查员的声明分解方法收集证据，确保证据相关性和真实性",
      "分析了不同声明分解方法对检索性能的影响，并评估其对验证流程结果的作用"
    ]
  },
  "Adaptive Transfer Scaling Laws for Multilingual Pretraining,   Finetuning, and Decoding the Curse of Multilinguality": {
    "主题": "多语言预训练的适应性迁移扩展规律",
    "场景": "针对多语言AI模型（覆盖400+训练语言和48评估语言）的预训练、微调和解码",
    "创新点": [
      "提出适应性迁移扩展规律（ATLAS），显著提升多语言场景的样本外泛化能力（R²提高0.3以上）",
      "通过跨语言迁移矩阵量化38×38语言对的相互收益，揭示语言间迁移特性",
      "提出语言无关的扩展规律，指导模型规模与多语言数据的最优配比，缓解多语言诅咒"
    ]
  },
  "Uncovering Systematic Bias in Quality Estimation   Metrics": {
    "主题": "机器翻译质量评估中的长度偏差",
    "场景": "机器翻译中无参考的质量评估（QE）指标的应用，如强化学习奖励信号和重排序等",
    "创新点": [
      "揭示QE指标普遍存在的两种长度偏差：对长翻译的过度错误预测和对短翻译的偏好",
      "提出两种缓解策略：训练时采用长度归一化和评估时引入参考文本"
    ]
  },
  "Toward Understanding the Transferability of Adversarial Suffixes in   Large Language Models": {
    "主题": "大语言模型的对抗性后缀可转移性",
    "场景": "离散优化攻击生成无意义后缀，诱导大语言模型输出违规内容",
    "创新点": [
      "提出三个与跨提示/模型攻击成功强相关的统计属性（原始提示激活拒绝方向强度、后缀对拒绝方向的偏移强度、正交方向偏移量）",
      "发现语义相似度与攻击成功的弱相关性，颠覆传统认知"
    ]
  },
  "Optimal Detection for Language Watermarks with Pseudorandom Collision": {
    "主题": "语言水印的最优检测",
    "场景": "大型语言模型（LLM）生成文本的可追溯性和责任归属，处理伪随机碰撞导致的依赖性问题。",
    "创新点": [
      "提出分层双层划分的统计框架，引入**最小单元**概念，处理单元间独立性与单元内依赖性的平衡。",
      "将水印检测建模为**极小极大假设检验问题**，推导出闭式最优检测规则，首次为伪随机不完美条件下的检测提供理论依据。",
      "揭示丢弃重复统计量提升性能的本质原因，并证明必须处理单元内依赖性以避免性能退化。"
    ]
  },
  "From Social Division to Cohesion with AI Message Suggestions in Online   Chat Groups": {
    "主题": "AI辅助社交凝聚力",
    "场景": "在线多轮政治讨论群组中的AI消息建议",
    "创新点": [
      "提出个性化与群体情境适应的LLM实时消息建议，对比分析对社交结构的影响",
      "发现关系型AI辅助（整合群体立场）比个体聚焦型更能增强异质群体间的包容性互动",
      "揭示语言风格的细微AI调节可重塑集体结构，为算法设计提供社会凝聚力优化路径"
    ]
  },
  "Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks": {
    "主题": "LLM越狱攻击中的心理说服机制",
    "场景": "利用社会心理学中的说服理论构建对抗性提示，突破大型语言模型的安全对齐机制",
    "创新点": [
      "首次将社会科学的经典说服理论（如心理操控策略）系统化应用于LLM越狱攻击的提示工程",
      "发现LLM在训练数据中习得的人类语言模式会导致其对结构化说服策略异常敏感",
      "揭示不同LLM具有独特的\"说服指纹\"，反映在其越狱响应的语言特征中"
    ]
  },
  "Performance Trade-offs of Optimizing Small Language Models for   E-Commerce": {
    "主题": "小型语言模型优化",
    "场景": "电子商务领域的多语言意图识别",
    "创新点": [
      "采用量化低秩适应（QLoRA）和合成数据集微调，使10亿参数的Llama 3.2模型达到与GPT-4.1相当的99%准确率",
      "提出硬件感知优化策略：4位GPTQ减少41%显存占用，GGUF格式在CPU上实现18倍推理加速和90%内存节省"
    ]
  },
  "Transformer Based Linear Attention with Optimized GPU Kernel   Implementation": {
    "主题": "Transformer线性注意力优化",
    "场景": "提高Transformer模型训练和推理效率，适用于大规模语言模型",
    "创新点": [
      "提出新型线性注意力前向与反向传播方法",
      "开发高度优化的CUDA内核实现，速度提升3.3倍，内存消耗降低3.6倍"
    ]
  },
  "A Stylometric Application of Large Language Models": {
    "主题": "大型语言模型在文本风格识别中的应用",
    "场景": "利用LLMs识别不同作者的写作风格，用于文学作品作者鉴定",
    "创新点": [
      "提出通过训练个人化GPT-2模型来捕捉特定作者的独特写作风格",
      "应用该方法验证争议作品的真实作者（如《Oz》系列第15本的作者归属）"
    ]
  },
  "Parallel Sampling from Masked Diffusion Models via Conditional   Independence Testing": {
    "主题": "并行采样掩码扩散模型",
    "场景": "离散文本生成，特别是长序列生成",
    "创新点": [
      "通过条件独立性测试识别令牌依赖关系，移除低置信度冲突令牌，实现高效并行解掩码",
      "提出模型无关的采样器PUNT，在保持生成质量的同时显著提升计算效率（IFEval基准准确率提升16%）",
      "诱导涌现式分层生成策略：先建立段落级结构再进行局部优化，实现类规划生成过程"
    ]
  },
  "Model-Aware Tokenizer Transfer": {
    "主题": "多语言大模型的Tokenizer迁移",
    "场景": "低资源或不同文字语言的Tokenizer适应问题",
    "创新点": [
      "提出Model-Aware Tokenizer Transfer (MATT)，利用Attention Influence Modeling (AIM)目标，将源模型的令牌间通信模式蒸馏到目标模型",
      "不同于仅依赖嵌入相似性的方法，MATT利用注意力行为指导嵌入初始化和适应"
    ]
  },
  "Explaining and Mitigating Crosslingual Tokenizer Inequities": {
    "主题": "跨语言分词不公平性",
    "场景": "多语言自然语言处理中的分词效率与成本",
    "创新点": [
      "通过训练约7,000个单语言分词器（覆盖97种语言），分析词汇量、预分词等因素对跨语言分词差异的影响",
      "提出通过调整词汇量或预分词策略（如超词分词器）显著降低跨语言分词溢价效应的方法"
    ]
  },
  "Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations": {
    "主题": "Few-Shot知识蒸馏",
    "场景": "在数据稀缺情况下，将大型语言模型（LLMs）的能力迁移到小型高效的学生模型",
    "创新点": [
      "提出反事实解释增强蒸馏（CoD），利用极小扰动反事实样本精准映射教师模型决策边界",
      "从统计和几何视角提供理论证明，反事实样本通过提供决策边界附近信息提升参数估计",
      "实验验证CoD仅需极少量样本（8-512个）+对应反事实样本即可超越基线方法"
    ]
  },
  "Rigorous Benchmarking of AI Agents with a Scientific Research   Suite": {
    "主题": "AI agents 科学评估基准",
    "场景": "科学研究的自动化辅助（如文献综述、实验复现、数据分析）",
    "创新点": [
      "提出首个针对科学研究全过程的AI智能体综合评估套件（AstaBench），涵盖2400+跨领域科学问题",
      "开发可复现的生产级科研环境，标准化工具接口以控制变量（如模型成本、工具访问）",
      "配套提供9类科学专用AI智能体基线，首次实现真实用户需求驱动的基准构建"
    ]
  },
  "The Universal Landscape of Human Reasoning": {
    "主题": "人类推理动态建模",
    "场景": "认知心理学、哲学和人工智能中人类推理过程的定量描述",
    "创新点": [
      "提出信息流追踪（IF-Track）方法，利用大语言模型（LLMs）作为概率编码器量化推理步骤中的信息熵和增益",
      "首次在单一度量空间中成功建模人类推理行为的通用景观，捕捉关键推理特征、系统错误模式和个体差异",
      "在IF-Track中调和单/双过程理论，揭示人工与人类认知的对齐及LLMs对人类推理过程的重塑作用"
    ]
  },
  "A General Reasoning Agent with Scalable Toolsets": {
    "主题": "通用推理智能体与可扩展工具集",
    "场景": "解决现实世界中需要外部工具和长期交互的复杂任务",
    "创新点": [
      "自主内存折叠机制，压缩交互历史为结构化记忆（情景记忆、工作记忆、工具记忆），减少错误积累",
      "端到端强化学习策略（ToolPO），利用LLM模拟API并赋予工具调用令牌细粒度信用"
    ]
  },
  "Upgrading Inference-Time Scaling for Stock Movement Prediction   with Large Language Models": {
    "主题": "大语言模型在股票走势预测中的应用",
    "场景": "金融领域中的股票走势三类分类（上涨、持平、下跌）任务，使用大语言模型进行独立逻辑推理和预测。",
    "创新点": [
      "提出反射性证据调优（RETuning），在强化学习前作为冷启动方法，鼓励动态构建分析框架并独立组织证据评分，减少上下文观点的不当影响。",
      "构建大规模多源数据集，涵盖2024年5,123只A股股票的长文本（32K tokens）和20万样本，整合价格、新闻、分析师观点、量化报告等多维度信息。"
    ]
  },
  "A Unified System for Multimodal Document Parsing and   Deep Research": {
    "主题": "多模态文档解析与深度研究",
    "场景": "多模态文档（包含文本、图表、公式等）的知识检索与深度问答",
    "创新点": [
      "提出**多模态深度解析技术**，保留文档布局与视觉语义，并生成多粒度表征（从片段到文档级）",
      "设计**动态混合检索架构**，支持纯文本、纯视觉及跨模态检索，并自动选择最优检索粒度",
      "开发**多智能体协同工作流**，通过任务分解、渐进式证据积累实现跨文档跨模态的答案生成",
      "构建首个多模态多跳多文档评测基准**M4DocBench**，填补现有评估能力空白"
    ]
  },
  "Creating the First Pragmatics   Understanding Benchmarks for Slovene": {
    "主题": "语言模型的语用理解评估",
    "场景": "针对斯洛文尼亚语的语用理解能力评估，创建首个基准测试",
    "创新点": [
      "首次为斯洛文尼亚语设计语用理解基准测试（SloPragEval和SloPragMega），包含405道多选题",
      "强调基准需基于原生数据设计，并验证其文化特异性与非字面含义理解能力",
      "通过人类基线对比发现专有模型与开源模型存在显著性能差距"
    ]
  },
  "Detecting   Phonotactic Inconsistencies in a Kokborok Wordlist": {
    "主题": "语言文档中的音系异常检测",
    "场景": "Kokborok词汇表中的音位配列不一致性检测，用于识别转录错误和未记录的借用词",
    "创新点": [
      "采用无监督异常检测方法，结合字符级和音节级音位配列特征，提高检测精度",
      "引入音节感知特征，显著优于传统字符级基线方法",
      "提出高召回率策略，为语言调查者提供系统性验证标记，提升低资源语言文档的数据质量"
    ]
  },
  "Powering Personalized, Standardized, and Trustworthy   Agentic Service in massive-agent Ecosystem": {
    "主题": "多智能体生态系统服务管理",
    "场景": "大规模多智能体生态系统中的个性化、标准化和可信服务管理",
    "创新点": [
      "提出ColorEcosystem框架，整合智能体载体、智能体商店和智能体审计三组件，实现规模化个性化服务（基于用户数据和数字孪生技术）。",
      "通过集中的智能体商店平台标准化管理多样化服务，解决服务分散问题。",
      "引入开发者与用户行为监督的审计机制，确保服务提供方和使用方的可信性与行为完整性。"
    ]
  },
  "Are the LLMs Capable of Maintaining at Least the Language Genus?": {
    "主题": "大语言模型（LLMs）的语言谱系敏感性",
    "场景": "探究LLMs在多语言环境下是否保持语言谱系结构的敏感性",
    "创新点": [
      "首次验证LLMs在提示语言保真度不足时倾向于切换至谱系相关语言",
      "发现LLMs在语言属（genus）内部的知识一致性显著优于跨属表现",
      "揭示训练数据资源可用性对属级效应存在强调节作用"
    ]
  },
  "Interpretable Signals for Detecting Hallucinations in   Retrieval-Augmented Generation": {
    "主题": "RAG系统中的幻觉检测",
    "场景": "检索增强生成（RAG）系统中检测模型输出与检索内容不一致的幻觉问题",
    "创新点": [
      "提出基于外部上下文评分和参数知识评分的机制化检测方法，分离两者贡献",
      "利用代理模型（Qwen3-0.6b）训练的分类器可泛化至其他大模型（如GPT-4.1-mini），实现跨模型评估",
      "发现幻觉的机制根源（高层FFN模块过度注入参数知识）并针对性设计信号指标"
    ]
  },
  "Document Understanding, Measurement, and Manipulation Using Category   Theory": {
    "主题": "基于范畴论的文档理解与处理",
    "场景": "多模态文档结构分析、信息度量及生成任务（如摘要、扩展）",
    "创新点": [
      "提出将文档建模为问题-答案对范畴的数学表示方法，实现结构化表征",
      "开发正交化信息分解技术，将文档内容划分为非重叠信息单元",
      "基于范畴论框架设计新型自监督方法（RLVR），利用组合性等约束改进预训练模型",
      "构建多模态扩展的数学框架，支持跨模态文档分析与生成任务"
    ]
  },
  "Deep Literature Survey Automation with an Iterative Workflow": {
    "主题": "自动化文献综述生成",
    "场景": "学术文献调研自动化，用于高效生成高质量文献综述",
    "创新点": [
      "提出迭代式工作流程（反复生成大纲并更新），提升检索质量和结构连贯性",
      "引入论文卡片（提炼核心信息）和可视化增强的循环优化机制，整合多模态内容（如图表）",
      "建立Survey-Arena评估基准，通过对比评测更准确衡量机器生成综述的质量"
    ]
  },
  "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair": {
    "主题": "LLM集成在代码生成和修复中的应用",
    "场景": "软件工程中多LLM集成用于代码生成和程序修复的场景",
    "创新点": [
      "揭示了LLM集成在代码生成和修复中的潜力，理论性能上限可超过最佳单模型83%",
      "提出基于多样性的候选解决方案选择策略，能实现理论潜力95%的效果"
    ]
  },
  "Probing Attention Specialization in Multimodal   Transformers": {
    "主题": "多模态Transformer中的注意力机制",
    "场景": "分析和编辑生成模型（语言和视觉-语言模型）中的注意力机制以理解并控制其输出",
    "创新点": [
      "提出基于信号处理的解释方法，系统分析注意力头对特定语义/视觉属性的专业化程度",
      "开发高效编辑方法（仅修改1%的注意力头）实现目标概念的定向抑制或增强",
      "在单模态和多模态任务（问答、毒性抑制、图像分类等）中验证注意力层的可解释可控结构"
    ]
  },
  "Brain-tuning Improves Generalizability and Efficiency of Brain Alignment   in Speech Models": {
    "主题": "脑调优预训练语言模型",
    "场景": "预训练语音语言模型与多人脑fMRI响应对齐，提高脑对齐效率与泛化性",
    "创新点": [
      "提出多参与者联合训练的脑调优方法，显著提升跨被试泛化能力",
      "实现5倍数据效率提升（新被试所需fMRI数据量减少80%）",
      "模型整体脑对齐度提升高达50%，并具有强跨数据集迁移能力",
      "反向增强下游语义任务表现，证实神经数据可优化AI语义表征"
    ]
  },
  "a Framework for Designing and Evaluating RAG vs. Prompt-Tuned LLM   Honeypots": {
    "主题": "基于LLM的蜜罐框架设计",
    "场景": "利用轻量级本地LLM提升蜜罐的上下文感知能力以增强攻击者交互",
    "创新点": [
      "提出SBASH框架，通过轻量级本地LLM解决云部署中的数据保护问题",
      "对比评估RAG支持与非RAG的LLM在Linux命令响应中的性能（响应时间、真实性、系统相似性）",
      "发现系统提示调优的LLM无需RAG即可达到未调优模型+RAG的准确率，且延迟更低"
    ]
  },
  "Enhancing Reasoning in Diffusion Language Models via Multi-Reward   Optimization": {
    "主题": "扩散语言模型的推理能力优化",
    "场景": "提高扩散语言模型在少去噪步数下的推理性能",
    "创新点": [
      "提出多奖励优化（MRO）方法，通过测试时间缩放、拒绝采样和强化学习优化跨去噪步的token相关性（包括序列内和序列间相关性）",
      "引入组步策略和重要性采样策略，降低奖励方差并提升采样效率"
    ]
  },
  "Does Model Size Matter? A Comparison of Small and Large Language Models   for Requirements Classification": {
    "主题": "语言模型在需求分类中的性能比较",
    "场景": "比较大型语言模型(LLMs)和小型语言模型(SLMs)在需求工程中的分类任务表现",
    "创新点": [
      "研究发现SLMs虽然规模小300倍，但性能接近LLMs，甚至在某些数据集上召回率更高",
      "揭示数据集特性对模型性能的影响大于模型规模本身",
      "提出SLMs作为LLMs的替代方案，具有隐私保护、低成本和本地部署优势"
    ]
  },
  "An Autonomous System Integrating Wearables and Multimodal Large   Language Models for Enhanced Remote Health Monitoring": {
    "主题": "远程健康监测系统",
    "场景": "通过可穿戴设备和多模态大语言模型实现远程病人监测",
    "创新点": [
      "集成多模态大语言模型（MLLMs），实现自然语言交互并检测病人活动与情绪状态",
      "结合物联网（IoT）与可穿戴设备，自动连续采集多种健康数据（生命体征、视频等）",
      "采用提示工程（prompt engineering）无缝整合病人信息，便于医护人员实时获取综合状态"
    ]
  },
  "Redefining Retrieval Evaluation in the Era of LLMs": {
    "主题": "检索评估优化",
    "场景": "基于大语言模型（LLMs）的检索增强生成（RAG）系统",
    "创新点": [
      "提出基于效用的标注框架，量化相关段落的正面贡献和干扰段落的负面影响",
      "设计UDCG（Utility and Distraction-aware Cumulative Gain）评估指标，采用面向LLM的位置衰减机制，直接优化端到端回答准确性的相关性",
      "实验证明UDCG相比传统指标（如nDCG）相关性提升高达36%，更贴合LLM对检索结果的消费模式"
    ]
  },
  "Let every token that has meaning bear its weight": {
    "主题": "希伯来语预训练语言模型",
    "场景": "自然语言处理（NLP）中的命名实体识别（NER）和情感分类任务",
    "创新点": [
      "从头训练基于RoBERTa的单语言编码器（HalleluBERT），使用49.1GB去重希伯来语网页文本和维基百科数据",
      "采用希伯来语专用的字节级BPE词汇表，突破现有模型在语料规模、词汇和训练深度上的限制"
    ]
  },
  "Human-Inspired Knowledge by Machine Agents through a Multi-Agent   Framework for Semi-Autonomous Scientific Conferences": {
    "主题": "AI驱动的半自主科学会议",
    "场景": "学术出版与会议流程的AI端到端集成",
    "创新点": [
      "首次实现AI全程参与学术流程（从论文生成、审稿到会议展示）",
      "提出结合语言模型与领域保护机制的新型学术协作框架",
      "探索AI作者身份认定与人机协作的研究新模式"
    ]
  },
  "Vision Language Models for Dynamic Human Activity Recognition in   Healthcare Settings": {
    "主题": "视觉语言模型在人类活动识别中的应用",
    "场景": "医疗场景中的远程健康监测",
    "创新点": [
      "引入描述性字幕数据集，填补视觉语言模型在人类活动识别中的评估空白",
      "提出全面的评估方法，解决动态和非确定性输出的评估难题",
      "实验证明视觉语言模型在准确性上媲美甚至超越传统深度学习模型"
    ]
  },
  "A Diagnostic Benchmark for Sweden-Related Factual Knowledge": {
    "主题": "瑞典语事实知识评测基准",
    "场景": "评估多语言模型对瑞典相关事实的回忆能力",
    "创新点": [
      "创建首个针对瑞典相关人物和事件的手工编写问答基准，弥补国际媒体覆盖不足的缺陷",
      "设计双语数据集（瑞典语/英语），支持跨语言事实一致性研究",
      "揭示模型规模与语言覆盖度的非线性关系（较小但瑞典语强化模型媲美大三倍的多语言模型）"
    ]
  },
  "Charting the Seas of Turkish NLP": {
    "主题": "土耳其语自然语言处理",
    "场景": "为形态丰富的土耳其语开发大规模预训练模型，解决其在大规模预训练中代表性不足的问题。",
    "创新点": [
      "首次为土耳其语提供基于RoBERTa的大规模编码器模型（SindBERT），包含基础和大型两种配置。",
      "通过对比实验揭示语料库质量和多样性对模型性能的影响，强调其在形态丰富语言中的核心作用，而非单纯数据规模。"
    ]
  },
  "Post-Processing for Bias Mitigation in Text-to-Image Models": {
    "主题": "文本到图像模型的去偏置后处理",
    "场景": "Stable Diffusion等文本到图像扩散模型生成图像时存在性别、种族等社会偏见的问题",
    "创新点": [
      "提出FairImagen框架，通过后处理调整提示嵌入（prompt embeddings）实现去偏置，无需重新训练模型",
      "集成公平主成分分析（Fair PCA），在保留语义的同时最小化群体特定信息",
      "引入经验性噪声注入和跨人口统计统一投影方法，可同时处理多属性偏置"
    ]
  },
  "Guided MCTS for Latent Space Exploration and Novelty   Generation": {
    "主题": "LLM驱动的创新生成框架",
    "场景": "提高大型语言模型在创意生成中的新颖性和突破性",
    "创新点": [
      "采用蒙特卡洛树搜索（MCTS）结合分层引导系统，通过\"语义罗盘\"向量实现长程定向探索",
      "提出基于景观感知的价值函数，替代自评估启发式，平衡内在一致性、外在新颖性和叙事进展",
      "通过正交投影构建的引导机制，有效避开训练数据中的\"引力阱\"，促进潜在概念空间的系统性探索"
    ]
  },
  "Multi-turn Training with Basic Human Feedback Helps Little on LLM   Reasoning": {
    "主题": "LLM推理训练策略比较",
    "场景": "大语言模型在多轮交互与单轮训练下的推理性能评估",
    "创新点": [
      "发现单轮训练模型在单轮和多轮评估中均表现更优，与传统观点相悖",
      "揭示多轮训练策略会导致单轮推理能力显著下降"
    ]
  },
  "Investigating Language Models'   Understanding of Scrambled Words": {
    "主题": "自然语言处理模型对拼写错误的鲁棒性",
    "场景": "评估语言模型（如BERT）对内部字母顺序混乱单词的理解能力",
    "创新点": [
      "量化分析英语单词在字母顺序混乱下的模糊性，利用英国国家语料库进行统计验证",
      "通过实验比较BERT在正常文本和字母混乱文本上的表现，发现性能下降低于预期",
      "提出单词歧义性低的上下文是模型鲁棒性的关键因素"
    ]
  },
  "A Benchmark for Adaptive Travel Planning under Disruptions": {
    "主题": "基于LLM的自适应旅行规划",
    "场景": "现实旅行中遭遇突发中断（如航班取消、天气影响）时的行程调整",
    "创新点": [
      "提出首个评估LLM在中断条件下行程调整能力的基准TripTide，涵盖中断严重性、旅行者容忍度等多维指标",
      "设计三重评估体系：自动化指标（意图保持、响应性、适应性）、LLM自动评分、专家人工验证",
      "发现LLM在长行程中空间偏离减小但中断处理能力下降的权衡现象"
    ]
  },
  "Leverage Unlearning to Sanitize LLMs": {
    "主题": "LLM去记忆化隐私保护",
    "场景": "预训练大语言模型（LLM）微调场景中敏感信息泄露的防护",
    "创新点": [
      "提出SANI框架，通过\"擦除-修复\"两阶段（重置末层神经元+防敏感信息微调）实现低成本去记忆化",
      "针对性消除直接/间接标识符及预定义机密术语，显著减少信息泄露风险",
      "仅需少量训练轮次即可完成模型净化，适配医疗/企业等已训练模型的快速隐私处理需求"
    ]
  },
  "Efficient semantic uncertainty quantification in language models via   diversity-steered sampling": {
    "主题": "语言模型语义不确定性量化",
    "场景": "自由形式问答（QA）中评估语言模型的语义不确定性，适用于风险敏感场景",
    "创新点": [
      "提出多样性导向采样器，通过自然语言推理模型注入语义相似性惩罚，减少语义冗余输出",
      "采用重要性重加权和方差缩减技术，提升不确定性估计的准确性和稳定性",
      "模块化设计，无需访问基础语言模型梯度，可直接作为现有系统的即插即用增强"
    ]
  },
  "Mitigating Self-Jailbreak in Large   Reasoning Models with Chain-of-Guardrails": {
    "主题": "大型推理模型的安全防护",
    "场景": "防止大型推理模型在复杂任务中生成有害内容或被越狱攻击",
    "创新点": [
      "提出\"自越狱\"现象的分析，揭示模型虽具备拒绝不安全查询的能力但被削弱",
      "设计Chain-of-Guardrail框架，通过重组/回退不安全推理步骤维持安全轨迹",
      "实现安全性与推理能力的平衡，显著优于现有存在严重权衡缺陷的方法"
    ]
  },
  "Prompt-based Agents for Reinforcement Learning": {
    "主题": "基于提示的强化学习代理",
    "场景": "利用大语言模型（LLMs）作为强化学习代理，在不依赖自然语言的结构化环境中进行决策",
    "创新点": [
      "提出PARL方法，通过提示（无需微调）使LLMs作为强化学习代理，直接编码动作、状态和奖励进行交互学习",
      "针对非语言依赖任务（如网格世界位置解析）扩展LLMs的应用范围，超越传统语言相关任务局限"
    ]
  },
  "Tokenizing Personalized Context for Generative Recommendation": {
    "主题": "生成式推荐模型中的个性化语义ID生成",
    "场景": "在生成式推荐系统中，通过动态调整语义ID以反映用户个性化偏好",
    "创新点": [
      "提出动态个性化语义ID生成方法，结合用户历史交互数据改进传统静态映射方式",
      "打破通用物品相似性假设，实现同一物品在不同用户上下文中生成差异化语义表示",
      "实验验证该方法在NDCG指标上最高提升11.44%，优于非个性化基线"
    ]
  },
  "Sparser Block-Sparse Attention via Token Permutation": {
    "主题": "稀疏块注意力优化",
    "场景": "提高大语言模型（LLM）长上下文预填充的计算效率",
    "创新点": [
      "提出**PBS-Attn**方法，利用注意力机制的排列特性增强块级稀疏性，减少冗余计算",
      "设计定制化**permuted-FlashAttention内核**，实现端到端加速（最高2.75倍），同时保持模型精度接近完整注意力基线",
      "通过**动态块间关键令牌重分配**，解决传统块稀疏注意力中关键信息分散导致的次优稀疏问题"
    ]
  },
  "Understanding Network Behaviors through Natural Language   Question-Answering": {
    "主题": "自然语言处理的网络行为理解",
    "场景": "大型复杂网络的行为理解与配置管理",
    "创新点": [
      "提出树形配置分块策略，平衡语义连贯性与分割效率",
      "构建统一事实图作为中间表示，实现多厂商配置标准化",
      "设计混合命令式-声明式语言，减轻大语言模型的推理负担"
    ]
  },
  "Correlation Dimension of Auto-Regressive Large Language Models": {
    "主题": "大语言模型复杂性评估",
    "场景": "评估大语言模型生成文本的结构复杂性和质量",
    "创新点": [
      "提出基于分形几何的\"关联维度\"指标，量化文本的自相似性和长程结构复杂性",
      "揭示预训练过程中模型的三个阶段动态特征，并关联幻觉倾向等关键行为",
      "方法兼容Transformer/Mamba等架构，且对4bit量化保持鲁棒性"
    ]
  },
  "Analysing Migration-Related Tweets   in Right and Far-Right Political Movements": {
    "主题": "社交媒体极端主义分析",
    "场景": "欧洲右翼民粹主义背景下的移民相关推特话语研究",
    "创新点": [
      "结合先进自然语言处理技术与社会学视角，构建多学科分析方法",
      "开发英法双语MIGR-TWIT语料库，揭示仇恨言论与说服策略模式"
    ]
  },
  "Estonian Native Large Language Model Benchmark": {
    "主题": "爱沙尼亚语大语言模型评估",
    "场景": "评估不同大语言模型在爱沙尼亚语任务上的表现，填补该语言缺乏全面评测基准的空白。",
    "创新点": [
      "基于七种本土数据集的全面评估框架，涵盖语法、词汇、摘要等多维度能力",
      "首创结合人工评估与LLM-as-a-judge的双重评测方法，验证了Claude 3.7 Sonnet与人工评分的强一致性"
    ]
  },
  "Fusing taxonomy and artificial intelligence agents for   emergency medical services": {
    "主题": "AI增强的紧急医疗服务调度系统",
    "场景": "紧急医疗调度（EMD），处理呼叫者求助、模糊信息和高认知负荷的情境",
    "创新点": [
      "将临床分类法（32种主诉、6种呼叫者身份）与多智能体系统（MAS）结合，提高调度的临床合理性和情景多样性",
      "利用事实共享库（fact commons）确保交互的临床可信度，减少错误信息",
      "混合评估框架（医生人工评估+自动化语言分析），验证系统在调度有效性和指导效果上的高性能"
    ]
  },
  "Dynamic Multimodal Evaluation via Knowledge Enhanced Benchmark   Evolution": {
    "主题": "动态多模态评估框架",
    "场景": "多模态大语言模型(MLLMs)性能评估",
    "创新点": [
      "提出知识增强的基准演进(KBE)框架，将静态基准转化为可控制的动态演进版本",
      "通过重新选择视觉信息和融合外部文本知识双向重构问题集",
      "支持通过调节问题探索程度实现难度可控的评估"
    ]
  },
  "Reducing the Probability of Undesirable Outputs in Language Models Using   Probabilistic Inference": {
    "主题": "语言模型输出控制",
    "场景": "通过强化学习优化语言模型，减少不良输出概率的同时保持平均性能",
    "创新点": [
      "引入RePULSe方法，在标准强化学习损失基础上增加额外损失项，利用学习到的提案引导采样低奖励输出并降低其概率",
      "相比传统RL对齐方法，在期望奖励与不良输出概率的权衡上表现更优，且具有更强的对抗鲁棒性"
    ]
  },
  "Social Simulations with Large Language Model Risk Utopian Illusion": {
    "主题": "大语言模型社会模拟",
    "场景": "评估LLMs在模拟人类社交行为中的真实性及偏差风险",
    "创新点": [
      "提出多维度分析框架（五维语言指标）检测LLMs在社交模拟中的认知偏差",
      "首次揭示LLMs存在\"乌托邦幻觉\"（社会角色偏差、首因效应、积极性偏差）导致过度理想化社会表征",
      "通过聊天室式多智能体交互实验验证八种主流LLMs与真实人类行为的分歧"
    ]
  },
  "Taming Ambiguity in Unfaithfulness   Detection": {
    "主题": "大语言模型生成摘要的忠实性检测",
    "场景": "评估和改进大语言模型生成的摘要与源文档的忠实性",
    "创新点": [
      "提出新的忠实性标注框架，引入中间类别“Out-Dependent”以处理需要外部知识验证的情况",
      "构建新的不忠实性检测基准VeriGray，揭示现有SOTA模型在摘要任务中的幻觉问题"
    ]
  },
  "A Survey of   Integration Frameworks and Applications": {
    "主题": "大语言模型（LLM）与文本属性图（TAG）的集成框架与应用",
    "场景": "自然语言处理与图学习的交叉领域，应用于推荐系统、生物医学分析和知识密集型问答等",
    "创新点": [
      "提出首个系统化的LLM-TAG集成综述，从协同视角进行分类，包括LLM for TAG和TAG for LLM两个方向",
      "提出新颖的分类方法，将协同策略分为顺序、并行和多模块框架",
      "总结了TAG特定的预训练、提示和参数高效微调方法，并提供了可用的数据集和多样化的应用案例"
    ]
  },
  "Semantic Isotropy Predicts Nonfactuality in Long-Form   Text Generation": {
    "主题": "大语言模型长文本生成的可信度评估",
    "场景": "需要对大语言模型生成的长文本进行实时、低成本的可信度评估",
    "创新点": [
      "引入语义各向同性（semantic isotropy）概念，通过文本嵌入在单位球面上的分布均匀性来评估文本非事实性",
      "无需标注数据、微调或超参数选择，兼容开源和闭源嵌入模型",
      "在多种领域验证优于现有方法，仅需少量样本即可高效预测非事实性"
    ]
  },
  "Aligning Large Language Models with Demonstrations   Only": {
    "主题": "大语言模型对齐方法",
    "场景": "利用演示数据进行大语言模型对齐，尤其在有限数据场景下",
    "创新点": [
      "提出Self-Rewarding PPO方法，结合SFT和PPO优势，实现更有效的演示数据对齐",
      "设计基于SFT模型与预训练基模型对数策略比的隐式奖励函数，无需人类偏好标注即可进行策略内微调"
    ]
  },
  "Designing and Evaluating Hint Generation Systems for Science Education": {
    "主题": "教育科技中的提示生成系统",
    "场景": "中学科学教育中利用大语言模型生成学习提示",
    "创新点": [
      "提出静态提示与动态提示两种策略，前者预生成固定提示，后者根据学习者进度动态调整",
      "通过实验揭示学习者对不同提示策略的偏好，并发现自动评估指标的局限性",
      "探索大语言模型在生成提示链中的应用，避免直接揭示答案以促进主动学习"
    ]
  },
  "Improving Indonesian Language   Question Answering": {
    "主题": "印度尼西亚语问答系统",
    "场景": "低资源语言的问答系统改进",
    "创新点": [
      "采用自适应检索增强生成（RAG）系统，通过分类器区分问题复杂度以动态调整回答策略",
      "利用机器翻译进行数据增强，解决印度尼西亚语数据集稀缺问题"
    ]
  },
  "A Chinese Drug Recommendation Dataset for Discharge   Medications in Metabolic Diseases": {
    "主题": "智能药物推荐系统",
    "场景": "基于电子健康记录（EHRs）的出院药物推荐，针对代谢疾病患者",
    "创新点": [
      "首个公开的中文代谢疾病出院药物推荐数据集（CDrugRed），填补非英语EHR数据稀缺的空白",
      "包含5,894条去标识化记录，整合患者人口统计、病史、临床过程等多维信息",
      "通过多篇先进大语言模型（LLMs）基准测试，验证数据集挑战性（最佳F1分数仅0.5648）"
    ]
  },
  "Dynamic Retriever for In-Context Knowledge Editing via Policy   Optimization": {
    "主题": "动态检索的知识编辑方法",
    "场景": "大型语言模型（LLMs）中基于上下文的静态知识更新",
    "创新点": [
      "提出动态检索器（DR-IKE），通过强化学习（REINFORCE）优化BERT检索器，按编辑效用排序演示样本",
      "引入可学习阈值动态裁剪低价值样本，根据任务难度自动调整提示长度（易任务缩短，难任务扩展）",
      "纯黑盒兼容方案，仅需前向传播即可实现知识编辑，显著降低延迟（41.6%）并提升成功率（+17.1%）"
    ]
  },
  "Modeling Hierarchical Thinking in Large Reasoning Models": {
    "主题": "大型推理模型的分层思维建模",
    "场景": "分析大型语言模型（LLM）在链式推理（CoT）中的分层思维策略及其应用改进",
    "创新点": [
      "提出基于**有限状态机（FSM）**的形式化框架，将模型推理过程抽象为离散状态（如初始化、演绎、回溯等），实现可解释的层次化分析",
      "通过状态转移序列可视化不同模型的推理轨迹，揭示其策略差异与潜在缺陷（如不确定估计不足）",
      "为模型训练和鲁棒性评估提供新工具，例如通过状态标注对比优化CoT生成"
    ]
  },
  "A Dataset for Scientific   Hallucination Detection": {
    "主题": "大语言模型科学幻觉检测",
    "场景": "科学文本生成领域中的多语言幻觉检测",
    "创新点": [
      "推出CAP数据集，覆盖9种语言（5种高资源、4种低资源），包含900个科学问题及7000+模型生成答案，支持跨语言研究",
      "提供细粒度标注（事实性错误标签和语言流畅性标签），结合token序列及logits数据，提升检测完整性",
      "针对性解决科学领域幻觉的特殊性（专业术语、统计推理、上下文依赖性），弥补现有LLM评估空白"
    ]
  },
  "Label Smoothing Improves Gradient Ascent in LLM Unlearning": {
    "主题": "大语言模型遗忘学习优化",
    "场景": "使大语言模型以低成本遗忘有害/不良知识，同时最大限度保留模型实用性",
    "创新点": [
      "提出平滑梯度上升（SGA）方法，结合遗忘数据与构造的正常数据，通过可调平滑率提高稳定性",
      "理论指导最优平滑率的选择，平衡遗忘效果与模型实用性",
      "在多个基准（TOFU、Harry Potter、MUSE-NEWS）上验证SGA优于原始梯度上升（GA）方法"
    ]
  },
  "Aesthetics and Quality Assessment of Visualizations": {
    "主题": "可视化美学与质量评估",
    "场景": "评估多模态大语言模型（MLLMs）在数据可视化美学与质量判断中的性能",
    "创新点": [
      "提出首个综合性基准VisJudge-Bench，覆盖32种图表类型、3090个真实场景样本，填补领域空白",
      "设计专有模型VisJudge，显著缩小与人类专家评判差距（MAE降低19.8%，一致性提升58.7%）"
    ]
  },
  "Reasoning Models Reason Well, Until They Don't": {
    "主题": "大型推理模型（LRMs）的性能限制",
    "场景": "评估语言模型在复杂推理任务（如数学、物理、医学）中的表现",
    "创新点": [
      "提出新数据集DeepRD，可生成复杂度可扩展的推理问题，用于更全面评估模型性能",
      "发现LRMs在足够复杂度下表现突然下降，无法泛化到训练分布之外的复杂问题",
      "分析现实世界知识图谱和证明数据集的复杂度分布，揭示LRMs的潜在失败风险"
    ]
  },
  "Mapping Faithful Reasoning in Language Models": {
    "主题": "语言模型推理忠实性分析",
    "场景": "评估链式思维（CoT）在语言模型中的真实性与内部计算关系",
    "创新点": [
      "提出Concept Walk框架，通过激活空间投影追踪模型内部立场沿概念方向的演变",
      "引入对比数据学习的概念方向分析，区分装饰性推理与忠实性推理",
      "在安全领域案例中验证方法，揭示简单任务与困难任务中CoT扰动的不同内部响应模式"
    ]
  },
  "Efficient Russian Language Embedding Model": {
    "主题": "俄语文本嵌入模型",
    "场景": "俄语文本处理与多任务评估（如检索、分类、聚类）",
    "创新点": [
      "提出三阶段训练流程（对比预训练、难负例微调、多任务泛化），统一多样化目标并利用合成数据生成",
      "引入双向注意力机制和潜在注意力池化技术，增强上下文建模与序列聚合能力",
      "通过剪枝25%的Transformer层显著提升效率，同时在俄语基准测试（ruMTEB）上达到SOTA性能（69.1分）"
    ]
  },
  "A Comparative Study Using Machine Learning   Models and Large Language Models": {
    "主题": "Urdu语言的讽刺识别",
    "场景": "在自然语言处理中，利用机器学习和大型语言模型进行Urdu语言的讽刺检测",
    "创新点": [
      "通过将英语讽刺语料库翻译成Urdu语言，扩展了低资源语言的讽刺识别研究",
      "创新性地比较了传统机器学习模型（如Gradient Boosting）与最先进的基于transformer的模型（如LLaMA 3）在Urdu讽刺检测中的表现"
    ]
  },
  "Faithful Adaptive Iterative Refinement for Retrieval-Augmented   Generation": {
    "主题": "检索增强生成（RAG）",
    "场景": "复杂多跳查询中的信息合成",
    "创新点": [
      "引入结构化证据评估（SEA）模块，将检索过程转化为动态证据驱动的推理过程",
      "提出自适应查询细化代理，通过明确识别信息缺口生成针对性的子查询",
      "采用迭代细化循环机制，确保证据充分性以保障生成结果的严格忠实性"
    ]
  },
  "A Dynamic Benchmark for Genuine Spatial Mathematical   Reasoning of VLMs in Solid Geometry": {
    "主题": "视觉语言模型在立体几何中的空间数学推理",
    "场景": "评估VLMs在动态立体几何问题中的空间推理能力",
    "创新点": [
      "提出首个动态基准DynaSolidGeo，支持从503个种子问题无限生成多样化的多模态实例，避免了静态数据集的记忆偏差。",
      "引入基于专家标注推理链的过程评估（逻辑有效性、因果连贯性），突破传统仅依赖最终答案的评测方式。",
      "通过半自动标注管道构建任务场景，涵盖心理旋转/可视化等高级空间智能需求的任务。"
    ]
  },
  "An Efficient, Explainable, and   Eco-friendly Approach to Large Language Modeling": {
    "主题": "内存基语言建模",
    "场景": "高效、环保的替代神经网络的语言模型，适用于需要低环境影响和透明性的场景",
    "创新点": [
      "提供线性对数扩展性能，实现高效的下一个词预测",
      "完全基于CPU运行，显著降低训练和推理中的碳排放",
      "结构简单且透明，增强模型可解释性"
    ]
  },
  "Multilingual Target-Stance Extraction": {
    "主题": "多语言目标立场提取",
    "场景": "社交媒体中多语言环境下对争议话题的目标及立场的自动识别",
    "创新点": [
      "提出首个多语言目标立场提取基准，涵盖加泰罗尼亚语、爱沙尼亚语、法语、意大利语、汉语和西班牙语",
      "扩展原单语言处理流程至多语言场景，无需为每种语言单独建模",
      "首次揭示目标立场提取的F1分数对不同目标表述的敏感性"
    ]
  },
  "A Large-Scale Dataset and Models for Vietnamese Automatic   Lyrics Transcription": {
    "主题": "越南语歌词自动转录",
    "场景": "越南音乐歌词转录，处理音调复杂性和方言变体",
    "创新点": [
      "创建首个大规模越南语歌词转录数据集（VietLyrics），包含647小时带行级对齐歌词和元数据的歌曲",
      "在VietLyrics数据集上微调Whisper模型，性能优于现有多语种歌词转录系统（如LyricWhiz）"
    ]
  },
  "Large-Scale and High-Quality Japanese Image-Text Pair Dataset for   Vision-Language Models": {
    "主题": "日语视觉-语言模型数据集",
    "场景": "为日语视觉-语言模型训练提供大规模高质量图像-文本对数据",
    "创新点": [
      "构建了WAON数据集（约1.55亿样本），通过过滤和去重技术提升数据质量",
      "开发了专门评估日本文化图像的WAON-Bench基准（含374类）",
      "基于WAON微调的模型在日语文化基准测试中达到SOTA性能"
    ]
  },
  "Supervised Fine-Tuning or In-Context Learning? Evaluating LLMs for   Clinical NER": {
    "主题": "临床命名实体识别（NER）",
    "场景": "比较不同方法（BERT类模型、GPT-4o的上下文学习、监督微调）在CADEC语料库上的性能",
    "创新点": [
      "发现简单上下文学习提示优于复杂指令提示",
      "监督微调（SFT）在GPT-4o上实现最高性能（F1≈87.1%）",
      "简化分类任务（两标签）可提升大语言模型（LLM）准确率"
    ]
  },
  "Reasoning Urban Socio-Economic Status in Vision-Language   Models via Reinforcement Learning": {
    "主题": "城市社会经济视觉感知",
    "场景": "利用街景和卫星影像通过多模态模型预测城市社会经济状况",
    "创新点": [
      "提出CityRiSE框架，通过强化学习优化大型视觉语言模型（LVLM）的推理能力",
      "设计可验证的奖励机制，引导模型关注语义相关的视觉线索",
      "实现跨城市和跨指标的泛化预测，显著提升预测准确性和可解释性"
    ]
  },
  "Enhancing Large Language Models with University   Course Materials": {
    "主题": "教育领域的大型语言模型增强",
    "场景": "大学计算机科学课程的AI学习助手",
    "创新点": [
      "提出并比较两种策略（检索增强生成RAG与持续预训练CPT），利用课程材料增强LLM的特定领域知识",
      "针对讲座幻灯片的多模态RAG方法，将检索内容以图像形式呈现，显著提升性能"
    ]
  },
  "Progressively Ascending Confidence Reward for LLM Reasoning": {
    "主题": "大型语言模型推理的信心奖励机制",
    "场景": "强化学习在大型语言模型推理中的应用，改进中间步骤的探索效率",
    "创新点": [
      "提出渐进上升信心奖励（PACR），直接从模型对正确答案的置信度动态计算密集奖励",
      "通过归纳偏置约束搜索空间，确保推理轨迹符合逻辑上升趋势",
      "实证表明PACR加速探索并在更少轨迹下达到奖励饱和，提升多基准性能"
    ]
  },
  "Disentangled Steering for LLM Personalization": {
    "主题": "LLM个性化控制",
    "场景": "通过激活引导调整LLM行为以适应不同用户偏好",
    "创新点": [
      "提出解耦式引导方法(SteerX)，分离偏好驱动与偏好无关的组件",
      "基于因果推理理论识别偏好驱动token并转化为连贯描述",
      "专注真实偏好信息生成更精确的激活引导向量"
    ]
  },
  "A Comprehensive Benchmark and Model Family for Patent Text   Embedding": {
    "主题": "专利文本嵌入模型",
    "场景": "专利文献检索、技术前景分析、专利分类与聚类",
    "创新点": [
      "提出PatenTEB综合基准，覆盖15项任务（检索/分类/聚类等），引入专利特有的非对称片段匹配和领域分层分割，解决现有基准不足问题。",
      "开发patembed多任务训练模型家族（6700万至3.44亿参数），支持4096token长上下文，在外部验证中刷新MTEB和DAPFAM数据集SOTA性能。",
      "揭示多任务训练增强泛化能力（尽管微损基准表现），并证明领域预训练初始化对任务族具有普适优势。"
    ]
  },
  "The Prompting Inversion": {
    "主题": "大语言模型提示工程优化",
    "场景": "数学推理任务（GSM8K基准测试）中提升大语言模型（GPT系列）的推理准确性",
    "创新点": [
      "提出“Sculpting”提示法，通过基于规则的约束减少语义模糊和常识错误，改进标准思维链（CoT）提示",
      "发现“提示反转”现象：约束性提示在中等模型（GPT-4）提升性能（97%→93%），但在先进模型（GPT-5）反成限制（94%→96.36%）",
      "揭示“护栏到手铐”机制：约束措施在高端模型引发过度字面化解读，提出模型能力与提示策略需协同演化"
    ]
  },
  "A Benchmark for Reliability Evaluation of LLMs in Paper Search   and Reading": {
    "主题": "LLM可靠性评估",
    "场景": "学术研究助手（论文检索与阅读）",
    "创新点": [
      "提出首个系统性评估LLMs在四项学术任务（引用检索、内容提取、论文发现、主张验证）可靠性的基准PaperAsk",
      "揭示LLMs在真实使用场景下的关键失效模式（如检索上下文失控膨胀、优先语义相关而非指令）",
      "开发基于轻量级分类器的可靠性检测方法，可识别不可靠输出"
    ]
  },
  "a probabilistic point of view": {
    "主题": "语言分离时间估计的概率模型",
    "场景": "通过词汇替换和渐变更新的随机过程分析语言分离时间",
    "创新点": [
      "引入词汇渐进修改的随机过程，以提高语言分离时间估计的精度",
      "从概率角度分析了现有Swadesh方法的基本假设的局限性"
    ]
  },
  "Determining Ease and Textual Clarity of German Text   Simplifications": {
    "主题": "德语文本简化评估",
    "场景": "自动文本简化（ATS）的质量评估，特别是针对德语文本",
    "创新点": [
      "引入DETECT，首个针对德语ATS的综合评估指标，涵盖简洁性、意义保留和流畅性三个维度",
      "利用LLM生成合成质量分数，无需人工标注即可创建数据集",
      "采用LLM驱动的细化步骤，使评分标准与简化需求对齐"
    ]
  },
  "Estimating the Error of Large Language Models at Pairwise Text   Comparison": {
    "主题": "大语言模型（LLMs）的成对文本比较误差估计",
    "场景": "测量LLMs在成对文本比较任务中的输出误差，不依赖真实标签，支持两种误差场景（均匀误差率与二元位置偏差）。",
    "创新点": [
      "提出不依赖真实标签的误差估计方法，支持两种误差场景（均匀误差率和位置相关误差率）。",
      "引入Copeland计数方法从成对偏好中构建文本排名，揭示LLM比较的可扩展性差并估计误差率。",
      "在六种LLMs和五种文本输入上验证方法一致性，发现位置偏差项接近均匀误差，且Claude表现最优。"
    ]
  },
  "Multi-Scale Alignment For CIF-Based Non-Autoregressive ASR": {
    "主题": "非自回归语音识别中的多尺度对齐",
    "场景": "提升连续集成-触发（CIF）机制在多语言语音识别中的稳定性",
    "创新点": [
      "提出多尺度CIF（M-CIF），通过字符和音素级监督增强子词表征的渐进对齐",
      "引入音素混淆错误（PE）和空格相关分割错误（SE）作为新评估指标，量化多级对齐效果"
    ]
  },
  "Error-Bounded Predictive Coding for Lossy Text   Compression (Episode I)": {
    "主题": "基于大语言模型的损耗文本压缩",
    "场景": "利用掩码语言模型实现高压缩比与可控重建质量的文本压缩",
    "创新点": [
      "提出误差有界预测编码（EPC），仅存储模型预测错误时的最小秩基校正，而非原始子集",
      "构建残差通道实现连续码率-失真控制，比传统预测掩码方法显著降低比特率",
      "通过精确比特核算与码率-失真分析验证算法优势，更高效利用模型内在知识"
    ]
  },
  "Synthetic Text and its Styles": {
    "主题": "大型语言模型的文本生成与风格分析",
    "场景": "探讨LLM生成文本在社会中的文化影响和意义构建",
    "创新点": [
      "提出“表面完整性”符号学方法，关注LLM在人类交流中的即时表现",
      "结合风格分析与传统深度批判，区分ML研究的三种知识兴趣（认知论、知识体系、认知学）",
      "通过案例研究揭示LLM作为文化参与者如何改变当代话语中的意义涌现和传播条件"
    ]
  },
  "A Benchmark Dataset for Sentiment and Reason Generation   for the Low-Resource Maithili Language": {
    "主题": "低资源语言的解释性情感分析",
    "场景": "为低资源语言Maithili构建首个情感分析与原因生成的基准数据集，支持可解释性研究。",
    "创新点": [
      "引入首个包含3,221句Maithili语料的情感极性及自然语言解释的标注数据集，填补资源空白",
      "数据集由语言专家验证，确保标签可靠性和语境保真性，且解释文本采用Maithili编写以增强文化相关性",
      "通过传统机器学习与Transformer模型实验验证数据集在可解释情感分析中的有效性"
    ]
  },
  "Federated Learning in a Dictatorship Setting": {
    "主题": "联邦学习中的恶意客户威胁",
    "场景": "去中心化模型训练中，恶意客户（独裁者客户）操纵全局模型",
    "创新点": [
      "提出“独裁者客户”新概念，能完全消除其他客户对服务器模型的影响",
      "分析多独裁者客户的复杂场景（协作/独立/背叛），提供理论收敛性证明",
      "在CV和NLP任务上实证验证理论攻击策略的有效性"
    ]
  },
  "Towards Human-Like and Hallucination-Safe Customer Service for   Retrieval-Augmented Dialogue": {
    "主题": "智能客服系统（RAG-based）",
    "场景": "基于检索增强生成的Web领域智能客服（社交平台/电商）",
    "创新点": [
      "提出两阶段学习框架（Learn-to-Think + Learn-to-Respond），模仿人类专家推理过程并结合强化学习自优化",
      "通过冷启动监督微调与自修正机制显著降低幻觉风险（业务错误率减少）并提升响应拟人化程度",
      "工业级A/B测试验证多场景性能（社区支持/直播互动场景解决率提升18.42%-28.92%）"
    ]
  },
  "A General Language-Guided Framework for Open-Set 3D Occupancy   Prediction": {
    "主题": "开放集3D占用预测",
    "场景": "自动驾驶或机器人导航中的动态/静态场景理解",
    "创新点": [
      "提出LOC通用语言引导框架，支持监督与自监督学习，适应多种占用网络",
      "采用多帧LiDAR点云融合与Poisson重建填补技术，结合KNN语义分配获得全面体素表征",
      "引入密集对比学习（DCL）缓解特征同质化，利用文本提示增强开放集识别能力",
      "在CLIP特征空间中预测体素特征，融合文本与图像信息实现无监督未知类别区分"
    ]
  },
  "Logarithmic Compression for Extending Transformer   Context Windows": {
    "主题": "Transformer长文本处理",
    "场景": "处理长上下文语言建模任务（如WikiText-103和PG-19基准测试）",
    "创新点": [
      "采用输入层对数压缩技术替代模型架构修改，保持Transformer原始结构简单性",
      "基于人类记忆认知模型的尺度不变压缩方法，提升长程上下文信息保留能力"
    ]
  },
  "Dynamic Sparse Neuron Masking for Lifelong   Knowledge Editing in LLMs": {
    "主题": "大语言模型中的终身知识编辑",
    "场景": "连续更新大语言模型（LLMs）中的过时知识，避免昂贵的全模型重训练",
    "创新点": [
      "提出细粒度的神经元级编辑框架（NMKE），结合神经元功能归因和动态稀疏掩码技术",
      "识别并区分知识通用神经元（跨提示激活）和知识特定神经元（特定提示激活）",
      "引入熵引导的动态稀疏掩码策略，精确定位目标知识相关神经元，减少参数修改量"
    ]
  },
  "Dynamic Decoding for Mode Steering": {
    "主题": "大语言模型推理模式控制",
    "场景": "提高大语言模型在推理和事实准确性任务中的可靠性",
    "创新点": [
      "提出基于信息瓶颈原理的理论框架，形式化区分泛化和记忆两种推理模式",
      "开发动态模式引导(DMS)算法，包括轻量级线性探测器和动态激活引导机制",
      "将DMS作为自适应自对比解码形式实现，显著提升逻辑一致性和事实准确性"
    ]
  },
  "Scaling General Reasoner to 1 Trillion Open   Language Foundation": {
    "主题": "大规模稀疏激活语言模型",
    "场景": "面向推理任务的可扩展语言基础模型开发",
    "创新点": [
      "提出高稀疏性的MoE架构（MTP机制），提升推理计算效率",
      "引入推理导向的中期训练思维链（CoT）激活方法",
      "采用全FP8训练及细粒度异构流水线实现万亿参数高效训练",
      "通过强化微调（DFT/Evo-CoT）优化模型推理能力"
    ]
  },
  "Mitigating Coordinate Prediction Bias from Positional Encoding Failures": {
    "主题": "多模态大语言模型的坐标预测偏差缓解",
    "场景": "高分辨率输入的视觉语言任务（如视觉问答、文档理解）中，精确坐标预测",
    "创新点": [
      "揭示视觉位置编码（VPE）扰动导致的方向性偏差规律（非随机误差），提出模型依赖内部位置先验的假设",
      "提出无需训练的测试时方法VPSG，通过辅助解码和轻量级有限状态机，利用扰动VPE生成负证据校正主预测",
      "实验证明该方法可提升高分辨率场景下坐标预测的鲁棒性"
    ]
  },
  "Embracing Trustworthy Brain-Agent Collaboration as Paradigm Extension   for Intelligent Assistive Technologies": {
    "主题": "脑代理协作（Brain-Agent Collaboration）",
    "场景": "智能辅助技术，尤其是针对重度神经障碍患者的脑机接口应用",
    "创新点": [
      "提出从传统脑机接口（BCI）向脑代理协作（BAC）的范式扩展，将代理视为主动协作伙伴而非被动信号处理器",
      "强调结合大语言模型（LLMs）理解复杂认知状态，突破传统BCI的低信息传输率和用户特定校准限制",
      "提出需关注伦理数据处理、模型可靠性和人机协作框架以确保系统安全可信"
    ]
  },
  "A Comprehensive Dataset for Human vs. AI Generated Text Detection": {
    "主题": "AI生成文本检测",
    "场景": "区分真实新闻文章与AI生成的文本，以提高内容真实性和可信度",
    "创新点": [
      "提供了包含5.8万份文本样本的大规模多样化数据集，结合真实文章和多款先进LLM生成的文本",
      "建立基线结果，支持区分人类与AI生成文本（准确率58.35%）及模型溯源（准确率8.92%）"
    ]
  },
  "Interpreting and Mitigating Unwanted Uncertainty in LLMs": {
    "主题": "大型语言模型不确定性缓解",
    "场景": "高风险领域中LLMs输出的不稳定行为（如正确回答翻转为错误）",
    "创新点": [
      "提出集成Needle-in-a-Haystack检索框架和Flip式重评估提示，模拟现实答案翻转场景",
      "发现非检索注意力头对误导性词语的过度关注是关键成因，掩蔽这些头可减少15%翻转行为，且不影响连贯性"
    ]
  },
  "Brain-Predictive Reasoning Embedding through   Residual Disentanglement": {
    "主题": "神经科学中的语言模型表征解耦",
    "场景": "利用解耦的LLM嵌入模型研究自然语言处理时的大脑活动",
    "创新点": [
      "提出残差解耦方法，分离出词汇、句法、语义和推理四个正交嵌入，避免传统编码分析中的特征混淆",
      "分离出的推理嵌入展现出独特预测能力，揭示了经典语言区之外的视觉区域参与及延迟神经响应特征",
      "证明传统LLM嵌入的预测优势主要来自浅层语言特征，掩盖了深层认知加工的神经信号"
    ]
  },
  "Reasoning via Per-Instance Program Synthesis": {
    "主题": "程序合成增强的大语言模型推理",
    "场景": "解决大语言模型在复杂多步推理（如算法、数学、视觉问答等任务）中生成不理想解决方案的问题",
    "创新点": [
      "提出实例级程序合成与优化方法（PIPS），通过结构反馈生成和细化程序，无需任务特定指导或显式测试用例",
      "引入动态置信度指标，灵活选择直接推理或程序合成方式",
      "在30个基准测试中显著提升性能（最高8.6%准确率提升），并减少65.1%的算法任务错误程序生成"
    ]
  },
  "Leveraging Large Language Models to Identify Conversation Threads in   Collaborative Learning": {
    "主题": "基于大语言模型的协作学习对话线程识别",
    "场景": "同步多人口语对话中的主题线索分析与协作学习行为编码",
    "创新点": [
      "提出同步多人口语对话中识别主题线程的系统化方法，填补异步文本与实时口语分析的技术空缺",
      "设计LLM提示策略优化方案，证明线程结构信息可显著提升对话行为（如赞同/补充/提问）的编码准确性",
      "揭示人机协同的实用平衡点，针对时间成本和精度需求提供混合分析路径"
    ]
  },
  "Exploration of Summarization by Generative Language Models for Automated   Scoring of Long Essays": {
    "主题": "生成式语言模型在自动作文评分中的应用",
    "场景": "使用生成式语言模型对长篇文章进行自动评分",
    "创新点": [
      "采用生成式语言模型（如GPT）代替传统基于编码器的模型（如BERT），突破512 token的长度限制",
      "结合摘要生成和提示技术提升长篇文章评分的准确性（QWK从0.822提升至0.8878）"
    ]
  },
  "A Vision-Language Model For Evaluating Handwritten Mathematics   Expressions": {
    "主题": "手写数学表达式评估",
    "场景": "教育技术中自动评估学生手写数学解题答案",
    "创新点": [
      "提出VEHME视觉语言模型，结合监督微调和强化学习两阶段训练，实现高精度且可解释的评估",
      "设计Expression-Aware视觉提示模块，增强对视觉异构输入的空间理解能力",
      "开源模型性能接近商用系统，提供可扩展的自动化数学评估工具"
    ]
  },
  "How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across   Diverse Occupations": {
    "主题": "AI与人类工作流程比较",
    "场景": "跨职业领域（数据分析、工程、计算、写作、设计）的AI代理与人类工作效能对比",
    "创新点": [
      "提出首个跨多领域（数据/工程/计算/写作/设计）的AI与人类工作流程直接对比框架",
      "开发可扩展工具包，将人机交互活动转化为结构化可解释的工作流",
      "揭示AI代理的程序化工作模式与人类UI中心化方法的本质差异"
    ]
  },
  "Cross-Lingual Stability and Bias in Instruction-Tuned Language Models   for Humanitarian NLP": {
    "主题": "多语言指令调优语言模型的人道主义NLP应用",
    "场景": "人道主义组织在使用商业API和开源模型进行多语言人权侵犯检测时的成本与可靠性权衡",
    "创新点": [
      "首次系统比较商业与开源LLMs在七种语言（含低资源语言）的人权侵犯检测性能，量化成本-可靠性关系",
      "提出四个新评估指标（CD/B/LRS/LSS）衡量跨语言可靠性，揭示对齐（alignment）而非模型规模决定跨语言稳定性",
      "发现对齐模型在类型学差异大的低资源语言（如林加拉语、缅甸语）中保持准确性，而开源模型存在显著敏感性和校准漂移"
    ]
  },
  "Scalable Supervising Software Agents with Patch Reasoner": {
    "主题": "软件代理监督与补丁推理",
    "场景": "利用补丁推理模型（R4P）为软件工程代理提供可扩展的奖励，替代传统基于测试的监督方法。",
    "创新点": [
      "提出R4P模型，通过推理验证补丁，无需构建繁重的测试沙箱或依赖高覆盖率的测试数据。",
      "采用组间目标进行强化学习训练，通过多补丁相互验证生成密集奖励，提升训练稳定性。",
      "R4P在高效性（50倍于传统测试速度）和准确性（72.2%验证准确率）上显著优于现有方法，并成功应用于轻量级框架Mini-SE，实现性能提升（Pass@1提升10%-32.8%）。"
    ]
  },
  "Iterative Layer Pruning for Efficient Translation Inference": {
    "主题": "模型压缩与翻译效率优化",
    "场景": "大型语言模型在机器翻译中的高效部署",
    "创新点": [
      "采用迭代式层剪枝策略，基于层重要性分析指导剪枝过程",
      "在保持基线模型翻译质量的前提下，显著减小模型规模并降低推理时间"
    ]
  },
  "Task Efficient LLMs with Task Aware Layer Elimination": {
    "主题": "大型语言模型推理优化",
    "场景": "提升LLMs在多种任务下的推理效率",
    "创新点": [
      "提出无需重训练的Task-Aware Layer Elimination算法，直接优化任务验证性能动态剪枝Transformer层",
      "首次通过互信息分析揭示任务瓶颈层，选择性移除可提升精度并降低计算成本",
      "支持用户灵活调节精度与效率的权衡，且在微调阶段应用可带来额外性能提升"
    ]
  },
  "A Dataset and Evaluation Framework for Multimodal Persuasion": {
    "主题": "多模态大语言模型（LVLMs）的劝说效应研究",
    "场景": "购物、健康、新闻等领域中多模态内容对LVLMs的劝说影响评估",
    "创新点": [
      "提出首个系统性研究框架MMPersuade，整合多模态数据集（含商业、主观行为及对抗场景的图文/视频）与量化评估指标（第三方协议评分和自我估计的标记概率）。",
      "揭示多模态输入显著提升劝说效果（尤其是误导信息场景），且先验偏好声明无法完全消除其优势。",
      "识别不同劝说策略的跨场景差异，如商业/主观场景中互惠策略最有效，对抗场景中可信度与逻辑占优。"
    ]
  },
  "How Temporal Biases Shape Retrieval in Transformer and   State-Space Models": {
    "主题": "语言模型中的时间偏向性",
    "场景": "大语言模型上下文学习中的时间与语义关系对信息检索的影响",
    "创新点": [
      "通过固定重复标记位置并置换其他标记，消除语义干扰，单独研究时间效应对下一个标记预测的影响",
      "发现无论变压器模型还是状态空间模型，都存在对输入序列开头或结尾附近标记的显著时间偏向性",
      "将变压器模型中的这种现象与归纳头(induction heads)联系起来，并通过消融实验验证"
    ]
  },
  "A French   Dialect Case-Study": {
    "主题": "低资源方言适配",
    "场景": "使用有限数据和计算资源对大语言模型进行法语方言（魁北克法语）适配",
    "创新点": [
      "采用低秩适应（LoRA）和计算高效的持续预训练（CPT）方法，仅更新不到1%的模型参数",
      "实验证明方言基准性能提升且标准语基准回归最小，语料库组成对效果影响显著"
    ]
  },
  "An Interrelated Multi-level Benchmark for Evaluating   Empathetic Speech Language Models": {
    "主题": "语音语言模型的共情能力评估",
    "场景": "评估SLMs在口语理解中整合非词汇声音线索和情感语境的能力，用于人机交互。",
    "创新点": [
      "提出首个多层次关联评测基准EchoMind，模拟共情对话的认知流程（内容理解、声音线索感知、综合推理、生成响应）。",
      "引入基于39种声音属性的共情评估框架，结合客观指标和主观评价，测试模型对高表达性声音线索的敏感性。",
      "揭示现有SLMs在指令遵循、自然语音适应性及声音线索利用上的缺陷，强调多模态整合的必要性。"
    ]
  },
  "Multi-Modal Fact-Verification Framework for Reducing Hallucinations in   Large Language Models": {
    "主题": "多模态事实验证框架",
    "场景": "检测和纠正大语言模型（LLM）生成内容中的事实性错误，适用于对准确性要求高的领域（如医疗、金融、科研）。",
    "创新点": [
      "**多源实时交叉验证**：结合结构化数据库、实时网络搜索和学术文献，动态校验LLM输出的准确性。",
      "**自动纠错保留流畅性**：在检测到错误时自动修正内容，同时维持回答的自然语言流畅性。",
      "**显著降低幻觉率**：实验显示可将LLM的虚构内容减少67%，且专家对修正结果的满意度达89%。"
    ]
  },
  "Actor-Critic Task-Completion with Look-ahead Action Simulation": {
    "主题": "基于认知模拟的网页任务自主完成",
    "场景": "新型网页环境中无需微调的自主任务执行",
    "创新点": [
      "提出ATLAS框架，通过认知空间的动作后果模拟实现环境模型驱动的规划",
      "采用模块化架构（认知地图构建-候选动作模拟-批评家优化-执行闭环），消除对网站特定LLM微调的依赖",
      "整合轻量级好奇心驱动探索构建动态环境认知模型"
    ]
  },
  "REVISION:Reflective Intent Mining and Online Reasoning Auxiliary for   E-commerce Visual Search System Optimization": {
    "主题": "电商视觉搜索系统优化",
    "场景": "淘宝电商平台中用户隐含意图与搜索系统响应不匹配的问题",
    "创新点": [
      "提出REVISION框架，结合离线意图挖掘与在线决策执行，自适应解决用户隐含需求",
      "利用大模型分析历史无点击请求，联合推理查询和商品元数据生成优化建议",
      "在线阶段通过训练模型REVISION-R1-3B，实现搜索流程端到端智能优化，降低无点击率"
    ]
  },
  "Your Text Embedding can Also be an Effective   and Efficient Listwise Reranker": {
    "主题": "文本嵌入模型统一检索与排序",
    "场景": "信息检索系统中高效检索和列表级重排序",
    "创新点": [
      "提出E²Rank框架，通过列表级排序目标持续训练单文本嵌入模型，实现高效检索与高质量重排序的统一",
      "设计基于余弦相似度的统一排序函数，利用候选文档增强的列表级提示模拟传统伪相关反馈（PRF）机制",
      "在保持基础嵌入模型效率的同时，显著提升重排序性能，在BEIR和BRIGHT基准测试中达到最优结果"
    ]
  },
  "Adaptive Multimodal Retrieval-Augmented Generation": {
    "主题": "自适应多模态检索增强生成",
    "场景": "多模态大语言模型（MLLMs）的外部知识检索与响应生成",
    "创新点": [
      "提出Windsock模块，动态决策检索需求与模态选择，降低计算开销并提升响应质量",
      "开发DANCE指令微调策略，增强MLLMs对检索信息的自适应利用及噪声鲁棒性",
      "利用MLLMs内部知识自评估，将问答数据集转换为MRAG训练数据"
    ]
  },
  "Critical Insights into Leading Conversational AI Models": {
    "主题": "大型语言模型（LLMs）对比分析",
    "场景": "企业、个人及行业应用中对不同LLMs的性能、道德及可用性评估",
    "创新点": [
      "首次系统性对比五大主流LLMs（Gemini, DeepSeek, Claude, LLaMA, GPT）在性能准确性、道德偏见缓解、易用性三方面的差异",
      "揭示各模型核心特性：Claude强道德推理、Gemini多模态优势、DeepSeek事实推理能力、LLaMA开源适用性、GPT均衡性能"
    ]
  },
  "Rule-Based Explanations for Retrieval-Augmented LLM Systems": {
    "主题": "检索增强生成（RAG）的LLM系统规则解释",
    "场景": "解释基于检索信息的LLM输出生成过程",
    "创新点": [
      "首次提出使用规则解释RAG-LLM系统的输出来源（如“若检索到特定排名文章，则LLM输出特定结果”）",
      "借鉴Apriori剪枝算法优化规则生成效率，避免暴力枚举所有检索组合"
    ]
  },
  "Single-pass Autoregressive LLM Structured Classification": {
    "主题": "LLM文本分类优化",
    "场景": "使用大型语言模型（LLM）进行高效准确的单次前向传播文本分类",
    "创新点": [
      "提出SALSA框架，结合结构化提示、类到标记映射和参数高效微调，避免冷启动训练",
      "通过将类别标签映射到唯一输出标记并限制模型响应为单标记，实现单次前向传播的高效分类",
      "在推理阶段仅投影相关类别标记的logits，提升分类准确性和效率"
    ]
  },
  "Conjugate Relation Modeling for Few-Shot Knowledge Graph Completion": {
    "主题": "知识图谱补全",
    "场景": "少样本知识图谱补全（FKGC），解决长尾分布和数据稀疏性问题",
    "创新点": [
      "提出共轭关系建模框架，结合高阶邻居信息聚合和隐式条件扩散关系学习",
      "采用流形共轭解码器，在流形空间高效推理缺失三元组"
    ]
  },
  "Detecting Boilerplate Responses with a Single Iteration": {
    "主题": "LLM响应效率优化",
    "场景": "检测大语言模型生成的模板化响应（如拒绝、简单确认等）以减少计算开销",
    "创新点": [
      "利用首个生成token的对数概率分布预测后续响应类型，实现单步检测",
      "基于轻量级k-NN分类器实现高准确率分类，可直接用于提前终止或重定向至小模型",
      "实验证明该方法适用于不同规模及专业领域的模型，显著降低计算成本"
    ]
  },
  "A Dataset for Multimodal Grounding Across Egocentric and   Exocentric Views": {
    "主题": "多模态数据集用于跨视角指代交流",
    "场景": "研究不同视角（自我中心与他者中心）对多模态指代理解的影响",
    "创新点": [
      "首创结合自我中心（智能眼镜）与他者中心（固定摄像头）的同步多模态数据（视线、语音、视频）",
      "引入3D场景重建技术，支持2D/3D和不同视角表示的对比研究",
      "构建包含2,707条标注指代表达的大规模厨房场景数据集（3.67小时）"
    ]
  },
  "A Unified Framework for Interactive SVG Generation with   Multi-modal Guidance": {
    "主题": "多模态交互式SVG生成",
    "场景": "数字设计与机器人控制中的可缩放矢量图形（SVG）生成",
    "创新点": [
      "提出首个统一的多模态框架（RoboSVG），支持文本、视觉和数值信号联合引导生成交互式SVG",
      "构建首个百万级数据集RoboDraw，涵盖四种SVG生成任务（如文本转SVG、图像转SVG等），支持系统性研究",
      "引入数值指导的候选SVG细化机制，显著提升输出质量与查询指令符合度"
    ]
  },
  "Morphological Analysis and Corpus   development of Endangered Toto Language of West Bengal": {
    "主题": "濒危语言数字化保护",
    "场景": "印度西孟加拉邦Toto语的文档化、数字化存档及推广",
    "创新点": [
      "开发三语（Toto-孟加拉语-英语）学习应用，集成Unicode文字与结构化语料库",
      "结合传统语言文档方法与AI技术（小语言模型和Transformer翻译引擎）",
      "首创形态分析框架，涵盖屈折/派生形态及文字标准化工具"
    ]
  },
  "Building the Health Infrastructure for   Everyday Insight and Guidance": {
    "主题": "个人健康管理基础设施",
    "场景": "全球范围内基于AI的实时健康监测与指导系统",
    "创新点": [
      "提出多模态数据融合的终身健康指导系统（PCU），实现个性化健康信息实时推送",
      "结合事件驱动模型和上下文推理，提供主动健康导航和医疗事件后持续康复评估",
      "突破传统阶段性诊疗模式，构建环境式自适应健康伴侣，整合个人传感与群体健康分析"
    ]
  },
  "Evaluating Commonsense Reasoning in Persian via Multiple-Choice   Sentence Completion": {
    "主题": "波斯语常识推理基准",
    "场景": "多选句子补全任务，用于评估波斯语常识推理能力",
    "创新点": [
      "提出PerCoR，首个大规模波斯语常识推理基准，包含10.6万道多选补全题，涵盖多种新闻和文化来源",
      "开发新型基于连词的分割策略生成结构多样化的句子补全对",
      "提出DRESS-AF对抗过滤方法（无需生成干扰项），通过相似度评分从候选集中筛选高混淆性干扰项"
    ]
  },
  "A Submission to the MRL 2025 Shared Task": {
    "主题": "多语言物理常识推理数据集",
    "场景": "为意大利语言和文化定制的物理常识推理评估基准",
    "创新点": [
      "创建首个基于意大利语言文化的物理常识推理数据集（FormaMentis），由母语专家标注并融入本地习俗",
      "数据样本兼顾双语（意大利语和英语），保留文化特异性以支持跨语言对比研究"
    ]
  },
  "Automating LLM Evaluation through Reciprocal Peer Assessment": {
    "主题": "自动化大语言模型评估",
    "场景": "动态、多样化的LLM评估，避免静态基准的测试集污染问题",
    "创新点": [
      "提出基于互评的动态评估框架（AutoBench），模型交替担任生成者、竞赛者和评估者角色",
      "引入迭代权重机制，增强可靠评估者的影响力，形成共识排名",
      "多法官设计显著优于单法官基线，评估结果更鲁棒且与人类评估一致"
    ]
  },
  "AdapTive and OptiMized dynamic temporal knowledge graph   construction using LLMs": {
    "主题": "动态时序知识图谱构建",
    "场景": "从非结构化文本中实时构建和更新时序知识图谱，用于实时分析、时序推理和动态记忆框架",
    "创新点": [
      "将输入文档分割为最小自包含的\"原子\"事实，提高提取的全面性和稳定性",
      "采用双时间建模，区分信息的观测时间和有效性时间",
      "并行合并原子时序知识图谱，显著降低延迟（90%以上）"
    ]
  },
  "Scaling Fine-Grained Style-Controlled Speech Conversations   for Spoken Dialogue Models": {
    "主题": "细粒度语音风格控制的对话模型",
    "场景": "提升语音对话模型在情感、速度、音量等多维度的风格控制能力，用于更自然的人机交互",
    "创新点": [
      "首次构建大规模细粒度语音风格控制数据集UltraVoice，覆盖6种语音风格维度（情感/速度/音量/口音/语言/复合风格）",
      "在保持核心对话能力前提下，微调模型使风格控制指标显著提升（MOS↑29-42%，指令遵循率↑14-40%）",
      "验证数据集可同步提升基础理解/推理/对话能力（URO-Bench基准+7.87-10.84%）及可控TTS模型训练效果"
    ]
  },
  "Semantic-Aware KV Cache Eviction with Adaptive Compression   Block Size": {
    "主题": "KV缓存压缩优化",
    "场景": "长上下文大型语言模型推理中的内存瓶颈问题",
    "创新点": [
      "提出语义感知的KV缓存驱逐框架（SABlock），通过语义分割对齐压缩边界与语言结构",
      "采用预算驱动的自适应块大小策略，在保证语义完整性的同时提升压缩效率",
      "结合段引导的令牌评分机制，优化令牌重要性评估，显著降低内存占用（46.28%）并加速解码（9.5倍）"
    ]
  },
  "Pedagogy-driven Evaluation of Generative AI-powered Intelligent Tutoring   Systems": {
    "主题": "智能辅导系统的生成式AI评估",
    "场景": "教育领域中基于生成式AI的智能辅导系统（ITS）的开发与评估",
    "创新点": [
      "提出基于教育学原理的评估框架，解决现有ITS评估中主观性和标准不一致的问题",
      "结合学习科学理论，提出三个切实可行的研究方向，以建立统一且可扩展的ITS评估方法",
      "通过真实案例研究，揭示当前评估实践中的挑战，为后续研究提供实践基础"
    ]
  },
  "A Closed-Loop Personalized Learning Agent Integrating Neural Cognitive   Diagnosis, Bounded-Ability Adaptive Testing, and LLM-Driven Feedback": {
    "主题": "个性化学习智能体",
    "场景": "智能教育中的个性化学习闭环系统",
    "创新点": [
      "提出端到端闭环框架（诊断-推荐-反馈），首次整合神经认知诊断模型（NCD）、能力边界自适应测试（BECAT）和LLM驱动反馈",
      "开发BECAT策略，基于诊断后验动态优化题目推荐，突破传统自适应测试的假设限制",
      "利用LLM将诊断结果转化为结构化、可执行反馈，解决传统反馈泛化问题"
    ]
  },
  "Are LLMs Ready for Real World Long Dependency Challenges?": {
    "主题": "大语言模型的长上下文理解能力评估",
    "场景": "现实世界长文本依赖任务（法律、金融、游戏、代码等领域）",
    "创新点": [
      "提出LooGLE v2基准，覆盖16k至2M token的真实长文本，自动生成多样化的长依赖QA任务",
      "设计10类领域特异性任务和1,934个实例，首次系统评估LLMs在实际长上下文场景中的表现",
      "揭示LLMs实际理解长度远低于宣称的上下文窗口，暴露其在长依赖任务中的显著缺陷"
    ]
  },
  "Scalable Oversight via Partitioned Human Supervision": {
    "主题": "AI系统的可扩展监督",
    "场景": "在多领域知识需求的高阶AI任务中，人类专家因领域局限无法直接评估或训练超人类表现的AI系统。",
    "创新点": [
      "提出基于互补标签（如专家指出错误选项而非正确答案）的无偏top-1准确率估计器，无需真实标签即可评估前沿AI系统",
      "设计两种混合估计器，结合稀缺普通标签与大量互补标签，显著降低监督信号获取成本",
      "提供有限样本偏差保证，理论验证互补标签及混合估计器的统计可靠性"
    ]
  },
  "Benchmarking Unlearning Misinformation in Multimodal Large   Language Models": {
    "主题": "多模态大语言模型中的信息遗忘",
    "场景": "针对足球转会谣言的多模态信息（文本+图像）选择性遗忘评估",
    "创新点": [
      "提出首个基于足球转会谣言的多模态遗忘基准OFFSIDE，包含15.68K手动标注数据，覆盖四种测试场景（遗忘效果、泛化性、实用性、鲁棒性）",
      "支持单模态遗忘（仅文本）和高级设置（选择性遗忘/纠正性再学习），首次揭示视觉谣言遗忘的普遍挑战",
      "通过实验发现当前方法存在五大缺陷（如单模态失效、提示攻击脆弱性等），暴露多模态遗忘技术漏洞"
    ]
  },
  "Evaluating Fine-Tuning and LoRA Trade-offs in Language   Models for Unfair Terms of Service Detection": {
    "主题": "语言模型在法律文本处理中的微调技术比较",
    "场景": "检测服务条款（ToS）文档中的不公平条款，应用于法律NLP领域",
    "创新点": [
      "系统评估了全参数微调、参数高效适配（LoRA、QLoRA）和零样本提示策略的性能，填补了法律领域专用模型优化的空白",
      "首次在ToS检测任务中验证了4-bit低秩适配（LoRA）技术可实现接近全微调性能（保留竞争性召回率）且内存成本降低3倍",
      "通过跨模型（BERT/DistilBERT/TinyLlama/LLaMA等）和多语种语料库实验，建立了法律文本处理微调的开放基准线"
    ]
  },
  "A Sociophonetic Analysis of Racial Bias in Commercial ASR Systems Using   the Pacific Northwest English Corpus": {
    "主题": "语音识别系统中的种族偏见分析",
    "场景": "评估商业ASR系统对不同种族背景说话者的转录准确性",
    "创新点": [
      "引入启发式确定的语音错误率（PER）度量，将识别错误与特定的社会语音变量关联",
      "分析了11种社会语音特征，发现元音质量变异（特别是低后元音合并和前鼻音合并模式）与跨种族错误率差异显著相关"
    ]
  },
  "Sub-token Utilization and Acoustic   Saturation in Multilingual ASR": {
    "主题": "多语言ASR中的子令牌利用与声学饱和",
    "场景": "分析多语言ASR模型（如Whisper）在不同语言推理过程中子令牌的利用模式及其声学饱和特性",
    "创新点": [
      "提出声学饱和时间（AST）概念，识别多语言ASR推理中令牌发现的稳定时间窗口",
      "发现子令牌利用模式与语言统计、类型和正字法结构强相关，而非训练数据规模",
      "揭示子令牌发现的秩-频分布符合Zipf-Mandelbrot定律，并与资源水平正相关"
    ]
  },
  "Frustratingly Easy Task-aware Pruning for Large Language Models": {
    "主题": "大语言模型任务感知剪枝",
    "场景": "在保持大语言模型（LLMs）特定任务性能的同时压缩模型参数规模",
    "创新点": [
      "通过结合通用领域和任务特定特征分布，改进现有剪枝算法中的重要性计算",
      "提出基于激活范数差异的参数分组（共享组与独占组）和分数融合机制，指导剪枝过程",
      "与多种基础剪枝技术无缝集成，在压缩模型时保留LLMs的领域专有能力"
    ]
  },
  "A Computational Investigation": {
    "主题": "计算语言学与声调起源",
    "场景": "通过计算模型研究藏语方言中声调起源的连续过程",
    "创新点": [
      "采用自动语音识别（ASR）性能量化音高在声调起源不同阶段的功能性作用",
      "提出基于ASR敏感性分析的\"声调起源连续体\"概念，揭示过渡系统中音高与音段线索的交互",
      "挑战传统最小对立对功能负载度量方法，指出其在过渡系统中可能高估音高依赖性"
    ]
  },
  "Collaborative Harmonization fOr Inference Robustness": {
    "主题": "LLM推理鲁棒性优化",
    "场景": "多角色大语言模型（LLM）在推理过程中因角色微小差异导致结果不一致的场景",
    "创新点": [
      "提出CHOIR框架，通过协同解码整合不同角色的推理信号，动态平衡路径分歧与一致性",
      "将角色差异重构为增强推理鲁棒性的资源，无需额外训练即可提升多人口统计组的平均性能19.2%",
      "框架在基础角色表现欠佳时仍保持有效性，最高可提升单一群体准确率26.4%"
    ]
  },
  "Performance of   Traditional and Transformer Models": {
    "主题": "希望语音检测",
    "场景": "社交媒体平台上的动机性表达识别",
    "创新点": [
      "比较传统机器学习模型与微调Transformer模型在希望语音检测上的性能，发现Transformer模型在精度和召回率上表现更优",
      "指出Transformer架构能捕捉希望言论中的细微语义，暗示大型语言模型在小数据集上可能有更好表现"
    ]
  },
  "Branch-and-Rethink Reasoning Reward Model": {
    "主题": "奖励模型优化",
    "场景": "大语言模型（LLMs）的强化学习对齐任务",
    "创新点": [
      "提出**分支-重思奖励模型（BR-RM）**，将\"二次思考\"机制引入奖励建模，通过两阶段评估（自适应分支选择+针对性重审）解决传统单次标量评估的注意力扩散问题",
      "设计**结构化双轮评估框架**：首轮聚焦实例关键维度（如事实性、安全性）生成假设，次轮针对性验证假设，提升对细微错误的敏感度",
      "采用**GRPO风格强化学习**训练，兼容标准RLHF流程，实验结果在多个领域达到SOTA性能"
    ]
  },
  "Unify Plan and Action for Universal Granularity Control": {
    "主题": "任务决策粒度控制",
    "场景": "大语言模型代理在多粒度决策任务中的应用",
    "创新点": [
      "提出Recode方法，通过统一代码表示将规划与动作结合，打破两者间的刚性分离",
      "采用递归分解机制动态调整决策粒度，从抽象函数逐步细化到原始动作",
      "利用递归结构自动生成多粒度训练数据，提升模型对层次化决策的学习能力"
    ]
  },
  "Variational Masked Diffusion Models": {
    "主题": "变分掩码扩散模型",
    "场景": "离散生成建模，特别适用于需要捕获标记间依赖关系的场景（如数独谜题和文本数据集）",
    "创新点": [
      "在掩码扩散过程中引入潜变量，显式建模标记间的依赖关系",
      "通过变分推断提升生成质量与全局一致性，突破标准掩码扩散的局限性"
    ]
  },
  "A U-Net and Transformer Pipeline for Multilingual Image Translation": {
    "主题": "多语言图像翻译",
    "场景": "从图像中检测、识别并翻译多语言文本",
    "创新点": [
      "采用定制U-Net和Tesseract结合，实现高精度文本检测与识别",
      "使用从头训练的Seq2Seq Transformer进行机器翻译，支持5种语言，强调定制化和适应性"
    ]
  },
  "Benchmarking Instruction Sensitivity for Large Audio Language   Models": {
    "主题": "大型音频语言模型的指令敏感性评估",
    "场景": "评估和提升大型音频语言模型（LALMs）对不同指令表述的鲁棒性，以增强其在音频理解任务中的稳定性。",
    "创新点": [
      "提出动态基准ISA-Bench，从指令描述、输出格式和任务组合三个维度系统评估LALMs的指令敏感性。",
      "通过构建复杂指令变体数据集微调Qwen2-Audio，显著提升了模型的指令遵循性能。",
      "首次揭示指令敏感性导致的性能下降问题，并指出在改进过程中可能出现的灾难性遗忘现象。"
    ]
  },
  "Less is More for Reasoning-Intensive Information Reranking": {
    "主题": "信息重排的轻量级LLM适配",
    "场景": "推理密集型信息检索任务（如科学文献搜索、知识密集型问题解决）",
    "创新点": [
      "提出LIMRANK-SYNTHESIZER合成管道，仅需5%训练数据即可生成高质量、多样化的重排样本",
      "轻量化模型LIMRANK在BRIGHT和FollowIR基准上实现与大数据训练相当的性能",
      "验证模型在科学搜索和检索增强生成等下游任务的强泛化能力"
    ]
  },
  "Towards a Foundational Visual-Programmatic Interface for   Code Intelligence": {
    "主题": "视觉-程序化代码智能接口",
    "场景": "多模态代码数据处理与生成，支持从文本指令、视觉输入或两者组合生成代码",
    "创新点": [
      "提出高效合成工具，构建最大规模多模态代码数据集JanusCode-800K",
      "开发统一视觉-程序化模型JanusCoder系列，支持多任务生成，性能接近或超越商业模型"
    ]
  },
  "a Multimodal, Multilingual, Multicultural, Multitask Real-World   Fact-Checking Dataset": {
    "主题": "多模态事实核查数据集",
    "场景": "针对多语言、多文化背景的真实世界虚假信息检测",
    "创新点": [
      "提出首个覆盖10种语言、22个文化背景的多模态真实世界数据集（M4FC），解决现有数据集规模小、语言单一问题",
      "整合6项跨模态任务（如视觉声明提取、定位验证等），首次实现端到端多任务联合分析",
      "采用专业事实核查机构验证数据，避免证据泄漏问题，提升可靠性"
    ]
  },
  "A Benchmark for Core Intent Identification in Personalized   Question Answering": {
    "主题": "个性化问答中的核心意图识别",
    "场景": "个性化问答系统，用于识别用户在问答过程中优先考虑的意图以生成满意回答",
    "创新点": [
      "提出核心意图（core intents）概念，通过用户行为模式（如答案选择）间接推断优先级意图，基于满意度理论（satisficing theory）",
      "构建IPQA基准测试（含多领域数据集），结合LLM标注、自动化验证与人工校验，填补现有评测仅关注回答质量而忽略意图识别的空白",
      "揭示当前语言模型在复杂问题中识别用户历史核心意图的不足，推动个性化问答领域研究"
    ]
  },
  "The First Multimodal Benchmark for AI Math Tutoring": {
    "主题": "AI数学辅导多模态基准测试",
    "场景": "评估多模态大语言模型（MLLMs）在数学辅导中的能力，包括问题解决、学生困难诊断和逐步指导",
    "创新点": [
      "提出首个AI数学辅导基准测试MMTutorBench，包含685个围绕教学关键步骤设计的问题",
      "为每个问题设计了针对性评分标准，支持六个维度的细粒度评估",
      "将基准测试结构化分为三项任务：洞察发现、操作制定和操作执行"
    ]
  },
  "Evaluating Large Language Models for Stance Detection on Financial   Targets from SEC Filing Reports and Earnings Call Transcripts": {
    "主题": "金融领域的大语言模型立场检测",
    "场景": "从美国证券交易委员会(SEC)文件财报和季度收益电话会议记录(ECTs)中分析对债务、每股收益(EPS)和销售额这三个核心财务指标的句子级立场。",
    "创新点": [
      "引入基于ChatGPT-3-pro标注并通过严格人工验证的句子级金融立场检测语料库",
      "系统评估了大语言模型(LLMs)采用零样本、少样本和思维链(CoT)提示策略的效果，发现少样本结合CoT提示性能最优"
    ]
  },
  "A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge   Integration": {
    "主题": "法律与网络安全知识整合",
    "场景": "法律与网络安全领域的信息整合与协作",
    "创新点": [
      "首次提出神经符号多智能体方法，整合法律案例与网络安全漏洞的复杂关联",
      "支持跨语言任务处理，突破传统法律研究工具的单领域局限"
    ]
  },
  "Towards Generalist Omni-Modal Reward Modeling with   Free-Form Preferences": {
    "主题": "通用多模态奖励模型",
    "场景": "AI行为与人类偏好对齐中的多模态支持和自由形式偏好捕获",
    "创新点": [
      "提出首个支持自由形式偏好的全模态奖励建模基准Omni-RewardBench，涵盖5种模态9项任务",
      "构建包含24.8万通用偏好对和6.9万指令调优对的多模态数据集Omni-RewardData",
      "开发融合判别式与生成式奖励模型的Omni-RewardModel，在跨模态任务中表现优越"
    ]
  },
  "Confidence-Guided Test-Time Scaling for Web Agents": {
    "主题": "LLM置信度引导的网页代理优化",
    "场景": "基于大语言模型（LLM）的多轮交互网页搜索代理场景中，利用置信度指导响应质量",
    "创新点": [
      "提出基于置信度的测试时调整方法（TTS），通过置信分数动态控制代理重试机制直至达到满意阈值，节省计算资源",
      "首次验证多轮交互场景下LLM置信度与任务准确性的强相关性（高置信度高准确率，低置信度近似零准确率）",
      "相比固定预算基线方法，在保持性能竞争性的同时显著减少token消耗"
    ]
  },
  "EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting": {
    "主题": "时间序列预测的混合专家模型",
    "场景": "时间序列预测（TSF）领域，应对近期数据和不可预测事件的挑战",
    "创新点": [
      "提出混合专家（MoE）框架，集成xLSTM、增强线性模型、PatchTST和minGRU等多种先进模型",
      "基于Transformer的MoE门控网络，动态整合互补且多样化的TSF模型",
      "在标准基准测试中性能优于现有所有TSF模型，包括最新的MoE方法"
    ]
  },
  "Detecting Religious Language in Climate Discourse": {
    "主题": "宗教语言检测",
    "场景": "气候变化相关文本中的宗教语言识别（来自宗教/非宗教组织的文本）",
    "创新点": [
      "提出双重方法：结合基于规则的分层宗教术语树模型与零样本LLM检测",
      "首次系统比较规则方法与LLM在宗教语言检测上的差异（规则法检出率更高）",
      "探讨宗教语言定义的二元争议（词汇 vs 上下文语义）"
    ]
  },
  "Benchmarking LLM Predictions of Labor Market   Changes": {
    "主题": "LLM劳动力市场预测评估",
    "场景": "评估大语言模型（LLM）对AI影响下的职业需求变化的预测能力",
    "创新点": [
      "提出首个结合高频行业级招聘数据与全球AI职业影响数据的基准，用于系统评估LLM的劳动力市场预测能力",
      "设计多策略提示方法（任务支架、角色驱动、混合），揭示结构化提示对预测稳定性的显著提升",
      "建立时间分割的评估框架防止信息泄漏，并开源基准以推动LLM经济推理研究"
    ]
  },
  "Simple and Efficient Knowledge Graph Generation from Textual   Data": {
    "主题": "知识图谱生成",
    "场景": "从文本数据中高效生成知识图谱，适用于低资源环境",
    "创新点": [
      "提出上下文集成图提取方法，减少对复杂语义处理的依赖，同时保留更多关键信息",
      "利用提取图的拓扑结构增强关系推理，无需依赖大型语言模型的复杂语言理解能力"
    ]
  },
  "Efficient Signalling in Dynamic Environments by   Projecting User Awareness across Future Timesteps": {
    "主题": "动态环境中的人机协作通信",
    "场景": "快速变化环境下的人机协作任务，需要优化信息传递时机以保持用户准确理解关键任务元素",
    "创新点": [
      "提出基于理性言语行为（RSA）框架的贝叶斯参考解析方法，动态规划消息序列以优化用户与环境认知对齐",
      "首次将RSA模型应用于动态环境通信及人机交互领域，结合多步预测与用户注意力模型提升信息传递效率",
      "通过自适应调整消息粒度与时机，兼顾用户个体差异和场景特性，实现认知资源的最优分配"
    ]
  },
  "Inference-Time Alignment for Large Language   Models": {
    "主题": "大型语言模型推理对齐",
    "场景": "LLM对齐任务中的推理阶段优化",
    "创新点": [
      "提出AdaSearch，基于初始响应词关键性假设的自适应块搜索策略，优化计算预算分配",
      "发展AdaBeam树搜索变体，扩展方法至序列解码任务",
      "在8个LLM上验证，相比Best-of-N基线在无害生成/情感控制/数学推理任务中胜率提升超10%"
    ]
  },
  "Arabic Children Speech Recognition Dataset": {
    "主题": "阿拉伯语儿童语音识别",
    "场景": "针对低资源阿拉伯语儿童语音数据稀缺问题，构建课堂环境下的儿童语音数据集",
    "创新点": [
      "发布首个Levantine阿拉伯语儿童语音数据集（Arabic Little STT），填补儿童专用语料库空白",
      "系统评估Whisper模型在儿童语音上的表现，揭示其WER（0.66）远高于成人数据（<0.20）",
      "提出严格伦理隐私框架，强调儿童敏感数据保护"
    ]
  },
  "Simulating Conversations from Read Literature for ASR and   Diarization": {
    "主题": "多说话人语音处理数据集",
    "场景": "为语音识别（ASR）和说话人日志（diarization）系统提供训练与评估的仿真对话数据集",
    "创新点": [
      "基于说话人感知的对话模拟（SASC），确保语义连贯性和真实对话时序，解决现有数据集中语义不连贯和时间间隔不自然的问题",
      "提出新颖的房间脉冲响应选择方法，通过空间合理性排名优化说话人-麦克风配置，平衡真实性与多样性",
      "结合外部VAD和压缩技术优化对话边界，利用同书籍的LibriTTS语句保持上下文一致性"
    ]
  },
  "Automated Data-Centric Pipeline and Multi-Model Collaboration   Training for Text-to-SQL Model": {
    "主题": "Text-to-SQL模型优化",
    "场景": "自动化数据修复与多模型协作训练提升Text-to-SQL任务性能",
    "创新点": [
      "提出全自动数据中心化流程（自适应数据修复和错误数据增强）",
      "设计多模型协作训练框架，通过不同增强数据训练互补模型",
      "采用集成策略整合多模型能力解决多选问题，提高准确率"
    ]
  },
  "Multi-Modal dataset and Comparative   Evaluation Results": {
    "主题": "多模态上下文感知识别",
    "场景": "单房间内多人重叠对话的场景识别",
    "创新点": [
      "提出MCoRec任务，结合音频、视觉和上下文线索解决鸡尾酒会问题",
      "引入非脚本化自然群聊数据集，包含极端语音重叠（高达100%）和高度分散的对话轮次",
      "展示视觉线索显著降低50%词错误率，突显多模态融合优势"
    ]
  },
  "Evaluating AI on Temporal and   Persona Reasoning": {
    "主题": "AI虚拟角色生成",
    "场景": "游戏、叙事和虚拟现实中基于命理学（BaZi）的动态角色生成",
    "创新点": [
      "创建首个基于八字命理（BaZi）的人物推理QA数据集，涵盖财富、健康、亲缘等现实人生维度",
      "提出BaZi-LLM系统，结合符号推理与大型语言模型，生成时序动态且细粒度的虚拟角色",
      "相比主流LLM（如DeepSeek-v3/GPT-5-mini），准确率提升30.3%-62.6%，错误命理信息导致准确率显著下降（20%-45%）"
    ]
  },
  "Code Aesthetics with Agentic Reward Feedback": {
    "主题": "代码美学优化",
    "场景": "提升大语言模型（LLM）生成代码的视觉美感",
    "创新点": [
      "提出多智能体奖励反馈系统（agentic reward feedback），联合评估代码可执行性、静态美学和交互美学",
      "开发GRPO-AR算法，将功能性与代码美学进行联合优化",
      "构建首个大规模代码美学微调数据集AesCode-358K及评估基准OpenDesign"
    ]
  },
  "A Specialized Arabic Language Model for Heritage Preservation   and User Intent Understanding": {
    "主题": "阿拉伯语专用语言模型",
    "场景": "阿拉伯语言理解、伊斯兰研究、文化遗产保护与用户意图识别",
    "创新点": [
      "采用原生阿拉伯语源训练，确保文化真实性和准确性，避免翻译数据导致的意图检测缺陷",
      "提出\"实用闭合架构\"，解决\"效用差距危机\"，将信息库转化为决策指引，减少用户重复提问",
      "结合古籍数字化OCR技术与多学科专家模块，兼顾文化遗产保护与通用知识领域性能"
    ]
  },
  "Are ASR foundation models generalized enough to capture features of   regional dialects for low-resource languages?": {
    "主题": "方言语音识别",
    "场景": "低资源语言的区域方言自动语音识别（ASR）",
    "创新点": [
      "开发了一个78小时标注的孟加拉语方言语音数据集（Ben-10），用于研究方言变异对ASR的影响",
      "发现语音基础模型在方言ASR（零样本和微调）中表现不佳，提出了方言特定模型训练的解决方案",
      "该数据集可作为低资源条件下ASR算法的分布外（OOD）评估资源"
    ]
  },
  "Drug-Drug Relation Extraction via Transfer Learning Method": {
    "主题": "药物关系抽取",
    "场景": "通过迁移学习从医学文本中提取药物间相互作用关系",
    "创新点": [
      "提出DREAM方法，利用预训练关系抽取模型构建药物关系本体",
      "结合大语言模型验证抽取结果，准确率达71%",
      "揭示医学领域关系抽取中的语义模糊性挑战"
    ]
  },
  "Predicting Domain-Adaptation   Performance at Unseen Pre-Training Budgets": {
    "主题": "域适应的预训练性能预测",
    "场景": "多语言预训练模型在目标域（英语/阿拉伯语→法语）的持续预训练（CPT）过程中，预测不同预训练预算下的适应性能",
    "创新点": [
      "提出PTPP-aware（单位参数token数感知）的自适应缩放律，将预训练预算作为显式变量，预测未见过的PTPP下的适应损失",
      "展示实际应用案例：在计算限制下规划回放比率和适应token预算，以满足目标和遗忘约束"
    ]
  },
  "Process Reward Models for Sentence-Level Verification of LVLM Radiology   Reports": {
    "主题": "医学影像报告生成验证",
    "场景": "自动化放射学报告生成中的临床关键幻觉检测",
    "创新点": [
      "提出轻量级句子级过程奖励模型（PRM），通过临床上下文和前置文本预测生成句子的正确性",
      "模型仅需0.5B参数，在弱监督标签下性能超越现有方法（如MCC提升7.5%）",
      "首次实现无需依赖模型内部状态的跨LVLM生成器泛化能力",
      "开发加权最佳N选策略，临床指标F1-CheXbert提升7.4%"
    ]
  },
  "Task-Driven Code Evaluation through Contrastive Learning": {
    "主题": "代码生成评估",
    "场景": "AI生成代码与开发者意图的匹配评估",
    "创新点": [
      "提出无参考评估指标MATCH，利用对比学习生成代码与自然语言任务描述的嵌入",
      "通过相似性评分衡量代码实现任务的准确性，优于现有指标（如CodeBERTScore、ICE-Score）",
      "支持多语言，与功能正确性和人类偏好相关性更强"
    ]
  },
  "Benchmarking Social Intelligence of Large Language Models in   Human-to-Human Conversations": {
    "主题": "大型语言模型社会智能评估",
    "场景": "评估大型语言模型在真实人类对话中的社会智能表现",
    "创新点": [
      "提出SI-Bench新基准，包含2,221段真实人类多轮对话，弥补模拟对话数据在真实语言风格和关系动态上的不足",
      "基于社会科学理论构建评估框架，覆盖8个模型的312段对话人工标注，发现SOTA模型在复杂社交情境推理上超越人类专家但在回复质量上仍有差距",
      "揭示思维链(CoT)推理在社会对话任务中可能导致性能下降的新现象"
    ]
  },
  "A Decomposed Approach to Well-Crafted   Screenwriting with LLMs": {
    "主题": "大语言模型（LLMs）在剧本创作中的应用",
    "场景": "使用LLMs生成高质量电视剧本，解决端到端生成方法在创意叙事和格式要求上的不足。",
    "创新点": [
      "提出双阶段优化框架（DSR），将创意叙事生成与格式转换解耦，分别优化模型在叙事构建和格式处理上的能力。",
      "采用混合数据合成方法解决训练数据稀缺问题，包括逆向合成（从剧本解构结构化输入）和正向合成（生成高质量叙事文本）。"
    ]
  },
  "The Perplexity-Entropy Equivalence": {
    "主题": "信息论与强化学习的交叉",
    "场景": "基于困惑度和熵的序列级权重分析",
    "创新点": [
      "提出GSPO序列级权重与困惑度比率和交叉熵变化的等效关系",
      "提供重要性权重的信息论解释，增强算法可解释性"
    ]
  },
  "Enhancing Low-Quality SFT Data via Neural-Symbolic Text Purge-Mix": {
    "主题": "低质量监督微调数据增强",
    "场景": "大规模语言模型（LLMs）在领域特定指令任务中的监督微调（SFT）",
    "创新点": [
      "提出神经-符号协同框架（ENTP），通过符号化净化（基于统计先验的噪声样本剪除）和神经重建（利用潜在表示和模型知识合成增强的指令-响应对）双重机制提升低质量数据价值。",
      "首次实现仅用低质量数据构建的增强数据集在五项指令跟随基准测试中超越13种主流数据选择方法，性能甚至优于完整原始数据集（约30万样本）的微调结果，揭示低质量数据的未开发潜力。",
      "结合符号方法的可解释性与神经模型的表征能力，同步提升数据信息密度和多样性，突破传统依赖质量过滤器的局限性。"
    ]
  },
  "Do They Matter?": {
    "主题": "形态学屈折变化任务中的频率信息应用",
    "场景": "自然语言处理中基于词频的形态屈折系统开发",
    "创新点": [
      "提出频率加权的训练-开发-测试集划分方法，提升模型对真实文本分布的适应性",
      "在评估中引入词例准确率（token accuracy），更贴合实际文本中高频词的重要性",
      "首创频率感知训练方法，将词频显式纳入采样过程，在43种语言中26种效果优于均匀采样"
    ]
  },
  "Token-wise Input-Output Projections for Efficient   Low-Rank Adaptation": {
    "主题": "大型语言模型低秩自适应优化",
    "场景": "提高预训练语言模型微调时的参数效率与性能",
    "创新点": [
      "提出动态调整低秩权重的方法（TopLoRA），根据输入token生成专有投影矩阵",
      "通过引入token级对角矩阵（Σ_X）实现细粒度适配，保持原低秩结构",
      "在不增加参数量的前提下，多项任务表现超越传统LoRA及其变体"
    ]
  },
  "A Single Small Model for Multilingual   Inflection": {
    "主题": "多语言词形变化模型",
    "场景": "多语言环境下从词基自动生成屈折形式的自然语言处理任务",
    "创新点": [
      "提出轻量级单模型架构，可同时处理73种语言的词形变化任务，性能超越单语言基线模型",
      "引入基于词频加权和词基分离的重采样方法，创建更真实的训练-开发-测试数据集划分"
    ]
  },
  "Leveraging Hierarchical Organization for Medical Multi-document   Summarization": {
    "主题": "医学多文档摘要生成",
    "场景": "利用层次结构改进医疗领域多文档信息的整合与摘要生成",
    "创新点": [
      "提出在输入中引入层次结构，相比传统扁平方法更能提升模型跨文档信息的组织能力",
      "通过GPT-4模拟评估与人工评估对比，验证层次结构在客观评价维度上的更高一致性",
      "首次证明模型生成的层次化摘要同时在事实性、覆盖度和人类偏好指标上优于人工摘要"
    ]
  },
  "A Survey on LLM Mid-training": {
    "主题": "大语言模型中的中间训练阶段",
    "场景": "在预训练和后期训练之间增加中间训练阶段，系统性地提升特定能力（如数学、编程、推理和长上下文理解）。",
    "创新点": [
      "正式定义了大语言模型中的中间训练阶段，强调其作为桥接预训练和后期训练的关键作用。",
      "提出涵盖数据筛选、训练策略和模型架构优化的优化框架，以系统性地增强指定能力。",
      "通过目标驱动的干预分析主流模型实现，展示中间训练在逐步提升大语言模型能力中的独特价值。"
    ]
  },
  "Efficient and Scalable Membership Inference for LLMs": {
    "主题": "大型语言模型成员推理攻击评估",
    "场景": "针对大型语言模型的成员推理攻击（MIA）评估，用于研究版权、安全和数据隐私问题。",
    "创新点": [
      "提供快速批量推理功能，显著降低大型语言模型推理的计算成本。",
      "实现统一的评估框架，集成了代表性的MIA方法，支持大规模实证比较。",
      "开源工具（Apache License 2.0）支持简单配置和可扩展性，便于实现可复现的基准测试。"
    ]
  },
  "Quality-Aware Translation Tagging in Multilingual RAG system": {
    "主题": "多语言检索增强生成系统中的翻译质量评估",
    "场景": "在多语言RAG系统中评估翻译质量以提升低资源语言的问答性能",
    "创新点": [
      "提出三维度翻译质量评估（语义等价性、语法准确性、流畅性），并将其作为元数据附加而不修改原文",
      "通过保留事实完整性，使生成模型能基于翻译可靠性做出决策，优于现有方法"
    ]
  },
  "A Multi-Aspect Prompting Framework for Time-Series Forecasting   with Large Language Models": {
    "主题": "时间序列预测的多方面提示框架",
    "场景": "利用预训练大语言模型（LLMs）进行时间序列预测",
    "创新点": [
      "提出多组件提示框架（MAP4TS），整合经典时间序列分析的全局域、局部域、统计及时序提示",
      "引入手工特征（自相关、偏自相关、傅里叶分析）增强模型对时序依赖性的捕捉",
      "实验证明小模型（如GPT-2）结合结构化提示超越大模型（如LLaMA）在长期预测中的表现"
    ]
  },
  "Towards Stable and Effective Reinforcement Learning for   Mixture-of-Experts": {
    "主题": "强化学习优化的专家混合模型训练",
    "场景": "针对专家混合（MoE）架构中强化学习训练的不稳定性问题",
    "创新点": [
      "提出基于路由器感知的重要性采样权重优化方法",
      "设计路由器逻辑引导的梯度方差缩减策略"
    ]
  },
  "Knocking-Heads Attention": {
    "主题": "注意力机制优化",
    "场景": "大规模语言模型中的多注意力头交互",
    "创新点": [
      "提出敲头注意力（KHA），实现注意力头间的特征级交互，通过共享对角初始化投影矩阵增强跨头表征",
      "在训练初期保持头特异性，允许模型逐步学习集成跨头表征，提升训练动态稳定性",
      "兼容多种现有注意力变体（如MHA/GQA/GTA），仅增加极少参数和计算量"
    ]
  },
  "Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated   Reinforcement Learning": {
    "主题": "工具增强的LLM评价模型",
    "场景": "大型语言模型（LLM）作为评估者，用于自动化评价响应质量",
    "创新点": [
      "提出端到端的强化学习框架TIR-Judge，整合代码执行器以提高评估精确度",
      "结合多样化训练（可验证与不可验证领域）、灵活评价格式（点式、对式、列表式）和无需蒸馏的迭代强化学习",
      "零样本训练的TIR-Judge-Zero达到与蒸馏变体相当的性能，展示工具增强模型的自我进化能力"
    ]
  },
  "A Unified and Universal Benchmark for AI-Generated Image   Content Detection and Localization": {
    "主题": "AI生成图像检测与定位基准",
    "场景": "评估和提升AI生成图像检测方法的泛化能力，覆盖多种生成模型和图像类别",
    "创新点": [
      "提出UniAIDet统一基准，涵盖文本到图像、图像到图像、修复、编辑及深度伪造等多样化生成模型",
      "首次整合摄影图像与艺术类图像，填补现有基准在端到端编辑和艺术图像检测的空白",
      "系统性分析检测与定位的泛化性能关系，为未来研究提供关键结论依据"
    ]
  },
  "A Large-Scale Multi-Category, Multi-Instance,   Multi-Relation Text-to-Image Benchmark": {
    "主题": "文本到图像生成评估",
    "场景": "评估多类别、多实例、多关系文本提示的图像生成对齐",
    "创新点": [
      "提出M³T2IBench基准，针对复杂多实例、多关系文本提示进行挑战性评估",
      "开发AlignScore评估指标，基于目标检测且与人类评价高度一致",
      "提出Revise-Then-Enforce后编辑方法，无需训练即可提升扩散模型的图像-文本对齐"
    ]
  },
  "A Personalised, Exercise-oriented English Language Learning   Tool Leveraging Large Language Models": {
    "主题": "个性化英语学习工具",
    "场景": "利用大型语言模型提供实时语法反馈和情景化练习的语言学习平台",
    "创新点": [
      "结合LangChain框架和大型语言模型开发个性化对话代理，实现实时语法纠正",
      "动态生成上下文相关的语言练习并追踪学习者长期能力提升",
      "系统架构实现高可用性验证，显著提升用户参与度与学习效果"
    ]
  },
  "An Investigation   of State Space and Hybrid Architectures": {
    "主题": "大语言模型架构比较",
    "场景": "知识驱动的上下文学习任务（ICL）评估",
    "创新点": [
      "揭示不同架构（Transformer/状态空间/混合模型）在任务表现相似时内部机制存在差异",
      "发现自注意力层和Mamba层是ICL功能向量的主要载体，并推测Mamba2采用不同于功能向量的ICL机制",
      "提出行为分析与机制分析结合的方法论框架"
    ]
  },
  "Can Language Models Compose Skills In-Context?": {
    "主题": "语言模型的技能组合能力",
    "场景": "语言模型在上下文示例中组合基本技能以完成复合任务",
    "创新点": [
      "揭示了语言模型在上下文组合基本技能时的负向影响，指出模型难以正确识别和组装技能",
      "提出理论分析表明，示例与组合步骤的对齐是关键影响因素",
      "基于理论分析设计了一种改进的探测方法，验证了对模型性能的提升"
    ]
  },
  "Assisting Language Models in Finding   Intricate Knowledge In Long Contexts": {
    "主题": "长文本上下文理解增强",
    "场景": "大语言模型在长且复杂上下文中的问答和推理任务",
    "创新点": [
      "提出TAG（标签增强生成）方法，通过轻量级数据增强提升模型性能，无需修改原始文档",
      "仅通过添加标签或标签定义到提示中，即可在32K长文本上实现17%性能提升"
    ]
  },
  "A Multi-Agent Debate Framework for Long-Form Factuality   Evaluation in LLMs": {
    "主题": "大型语言模型事实性评估",
    "场景": "高风险领域（生物医学、法律、教育）的长文本生成内容的事实性验证",
    "创新点": [
      "提出多智能体辩论框架（MAD-Fact），通过多视角验证机制解决长文本中复杂推理链的准确性评估问题",
      "构建首个中文长文本事实性数据集LongHalluQA，填补非英语语境评估空白",
      "引入事实重要性分级机制，量化长文本中不同主张的可信度权重"
    ]
  },
  "Measuring Teaching with LLMs": {
    "主题": "LLM驱动的教学评估",
    "场景": "利用定制化大型语言模型评估课堂教学质量，替代传统人工观察方法",
    "创新点": [
      "提出基于句子级嵌入的定制化LLM架构，优于传统子词标记化方法，尤其适合处理长篇幅、需解释的课堂转录文本",
      "在数据高效训练方案下系统评估五种句子嵌入模型，实现超人类表现（专家评分相关性>0.65，超越人工评分者间一致性）",
      "发现与人类判断更对齐的模型更关注课程级特征（而非孤立语句），挑战单轮标注范式的有效性",
      "验证模型聚合分数与教师增值测量的相关性，证明其捕捉到影响学生学习的特征"
    ]
  },
  "The Open-Ended Homogeneity of Language Models (and   Beyond)": {
    "主题": "语言模型输出多样性评估",
    "场景": "评估语言模型在开放域查询中的生成多样性，防止模型同质化对人类思维的长期影响",
    "创新点": [
      "提出首个用于系统性研究开放域查询的大规模数据集Infinity-Chat，包含26K真实用户查询及31K人工标注",
      "建立首个涵盖6大类17子类的开放域提示分类体系，揭示语言模型存在\"人工蜂群效应\"（模型内重复和模型间同质化）",
      "发现模型在引发个体差异化偏好时的评分校准缺陷，为AI安全研究提供新方向"
    ]
  },
  "Modeling Political Discourse with Sentence-BERT and BERTopic": {
    "主题": "政治话语分析",
    "场景": "社交媒体（Twitter）上的美国国会政治话题演化与道德价值观关联分析",
    "创新点": [
      "结合BERTopic主题建模与道德基础理论（MFT），提出动态话题演化追踪框架",
      "道德价值观（如Care/Loyalty）对话题持久性的影响",
      "量化话题持久性指标，揭示宏观主题稳定但微观话题易逝的规律",
      "揭示党派差异通过不同道德框架策略（如自由派侧重Care，保守派侧重Loyalty）体现"
    ]
  },
  "Offline Preference Optimization via Maximum Marginal Likelihood   Estimation": {
    "主题": "大型语言模型偏好对齐",
    "场景": "离线优化人类偏好对齐，简化现有方法（如RLHF）的复杂性和不稳定性",
    "创新点": [
      "提出基于最大边缘似然（MML）的偏好优化方法（MMPO），无需显式奖励模型和熵最大化",
      "理论证明MMPO通过隐式偏好优化产生加权梯度，自然提升优选响应权重",
      "实验表明MMPO超参数鲁棒性更强，在保持基础模型语言能力的同时实现更优偏好对齐"
    ]
  },
  "Language Server CLI Empowers Language Agents with Process Rewards": {
    "主题": "语言服务器与语言代理协同优化",
    "场景": "通过CLI工具桥接语言服务器协议（LSP）与编程代理/CI，提升代码编辑的确定性和可复现性",
    "创新点": [
      "提出**Selector DSL**与重定位算法，超越传统行列定位，支持符号化/AST路径/内容锚点等健壮寻址方案",
      "设计**确定性分析包**（Analysis Bundles），标准化语言服务器响应并封装环境/能力元数据，确保内容哈希稳定",
      "引入**安全操作沙盒**，支持预览、工作区隔离及Git感知的事务性代码变更（如重命名、代码动作）",
      "开发**过程奖励函数**，基于语言服务器事实（诊断增量、消歧置信度、安全应用检查）实现在线计算与离线复现，适用于过程监督与反事实分析"
    ]
  }
}