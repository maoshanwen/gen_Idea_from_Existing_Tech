{
  "Generating Style-Following and Expressive Pitch Curves for   Versatile Singing Tasks": {
    "主题": "歌唱音高曲线生成",
    "场景": "多任务歌唱应用（如音高校正、歌声合成、声码转换等）",
    "创新点": [
      "通过参考音频学习歌手风格，增强个性化表达",
      "基于整流流匹配架构，结合符号乐谱和音高上下文生成",
      "无需重新训练即可适配多种歌唱任务，提升泛化能力"
    ]
  },
  "Instrument Generation Through Distributional Flow Matching   and Test-Time Search": {
    "主题": "虚拟乐器生成",
    "场景": "生成具有跨音高和速度一致音色的虚拟乐器",
    "创新点": [
      "采用分布流匹配（DFM）方法，将速度场参数化为高斯分布，通过负对数似然优化，以表达预测中的不确定性",
      "引入基于模型置信度的测试时搜索策略，抽样多条轨迹并选择最大化音色一致性的输出",
      "结合音乐特定的音色一致性目标，提升专业级虚拟乐器的实时演奏效果"
    ]
  },
  "Aligning a Frozen Latent Text-to-Audio Model to Video": {
    "主题": "跨模态视频-音频对齐模型",
    "场景": "视频引导的音效生成（Foley）控制",
    "创新点": [
      "**轻量级跨模态桥接**：仅训练小型交叉注意力模块连接冻结的视频与T2A预训练模型，保留单模态性能的同时实现同步。",
      "**动态细粒度控制**：视频嵌入优化生成音频的时序与局部动态，而文本提示保持全局语义，兼顾可控性与同步性。",
      "**模块化可扩展设计**：支持视频编码器或T2A主干的灵活替换/升级，无需端到端重训练，降低计算成本。"
    ]
  },
  "Efficient General-Purpose Vocal Restoration": {
    "主题": "语音恢复技术",
    "场景": "消费设备语音/歌声录音的多重退化修复（噪声、混响、频带限制、削波等）",
    "创新点": [
      "提出轻量级单阶段模型SRS，直接在复数STFT域实现端到端修复，结合相位感知损失提升频率分辨率",
      "构建极端退化评测基准EDB（含87条严苛声学条件下的录音），填补多退化联合评估空白",
      "在iPhone 12 CPU实现10.5倍实时运算效率，非语音专项训练下性能逼近商业系统"
    ]
  },
  "Flexible Single- and Multi-Channel Speech Separation and   Enhancement": {
    "主题": "语音分离与增强（SSE）系统",
    "场景": "可变输入（麦克风阵列配置）和输出（说话人数量）的语音分离与增强",
    "创新点": [
      "提出FlexIO系统，支持通过提示向量（prompt vectors）实现任意数量说话人的条件分离",
      "设计阵列无关的通道通信机制，兼容多通道混合输入（1-5个麦克风）",
      "证实系统在真实数据（CHiME-4）上的鲁棒性，覆盖1-3说话人场景"
    ]
  },
  "Are These Even Words? Quantifying the Gibberishness of Generative Speech   Models": {
    "主题": "生成语音模型的非侵入式质量评估",
    "场景": "评估生成语音模型输出的无意义语音（胡言乱语）质量，尤其在无监督环境下",
    "创新点": [
      "提出基于语言模型的完全无监督方法，量化生成语音的胡言乱语程度",
      "发布高质量合成胡言乱语音数据集，促进语音可信度评估工具开发"
    ]
  },
  "Compressing Quaternion Convolutional Neural Networks for Audio   Classification": {
    "主题": "四元数卷积神经网络压缩",
    "场景": "音频分类任务（音乐类型识别、环境声音分类、语音情感识别）",
    "创新点": [
      "提出剪枝方法压缩四元数CNN，在保持性能的同时减少50%计算开销和80%参数量",
      "相比知识蒸馏，剪枝方案计算效率更高且性能更优",
      "验证了压缩后模型在多个音频数据集（AudioSet/GTZAN/ESC-50/RAVDESS）的泛化能力"
    ]
  },
  "Improving Baleen Whale Call Detection with Boundary   Proposal Networks and Post-processing Optimisation": {
    "主题": "鲸鱼叫声检测优化",
    "场景": "海洋音频中的须鲸叫声识别",
    "创新点": [
      "引入边界提议网络（BPN），利用骨干分类模型的中间潜在表示减少误检，提高精确度",
      "提出两种后处理超参数选择方法（前向搜索和后向搜索），分别优化事件级和帧级超参数，显著提升性能"
    ]
  },
  "A High-Fidelity 7th-Order Ambisonic Room Impulse Response   Dataset": {
    "主题": "高阶Ambisonic房间脉冲响应数据集",
    "场景": "复杂室内环境下的空间音频算法开发",
    "创新点": [
      "提出混合声学模拟方法（低频波模拟+高频射线追踪）生成7阶HOA-RIRs",
      "结合3D-FRONT真实场景建模，首次提供含复杂家具的高保真Ambisonic数据集",
      "覆盖全频段（0-20kHz）且包含详细声学参数统计（RT60、吸声属性等）"
    ]
  },
  "Robust Distortion-Free Watermark for Autoregressive Audio Generation   Models": {
    "主题": "抗篡改水印技术",
    "场景": "自回归音频生成模型的真实性验证",
    "创新点": [
      "提出Aligned-IS水印，基于聚类等效处理解决重令牌化不匹配问题",
      "在主流音频生成平台验证，显著提升水印检测率且保持音质无损"
    ]
  },
  "Taming Neural Speech Coding for Extreme Low-Resource   Scenarios": {
    "主题": "神经语音编解码框架",
    "场景": "极低资源条件下的语音编解码（计算功耗<700 MFLOPs，延迟<30 ms，支持1kbps/6kbps双速率）",
    "创新点": [
      "采用非对称频时架构优化资源分配，减少传统解码器的资源分散问题",
      "提出循环校准与精调（CCR）训练策略，避免模型陷入局部最优",
      "引入噪声不变性微调流程，增强模型在真实噪声环境下的鲁棒性"
    ]
  },
  "A Lightweight Streaming Codec in the Compressed Spectrum   Domain": {
    "主题": "轻量级音频编解码器",
    "场景": "语音压缩与语音语言模型中的音频表示",
    "创新点": [
      "在压缩频谱域中进行多尺度建模，提升效率和表示能力",
      "仅使用交替的CNN和RNN层，计算量和参数分别降至主流方法的20%和10%",
      "在4kbps低码率下性能优于现有轻量级架构"
    ]
  },
  "Evaluating Multimodal Large Language Models on Core Music Perception   Tasks": {
    "主题": "多模态大语言模型的音乐感知能力评估",
    "场景": "评估多模态大语言模型在核心音乐感知任务（如切分音评分、转调检测、和弦质量识别）中的表现，区分听力和乐谱阅读能力。",
    "创新点": [
      "提出三种核心音乐技能评估框架（Syncopation Scoring等），明确区分音频与MIDI输入的感知差异。",
      "首次将逻辑推理框架LogicLM适配音乐领域，结合符号求解器增强结构化推理能力。",
      "揭示了当前模型在音频感知上的明显短板（MIDI近满分但音频准确率骤降），为音频优先的音乐系统提供改进方向。"
    ]
  },
  "Multimodal Room Impulse Response Generation Through Latent   Rectified Flow Matching": {
    "主题": "多模态房间脉冲响应生成",
    "场景": "虚拟现实、建筑声学、音频制作中的高质量声学模拟",
    "创新点": [
      "提出两阶段生成框架（变分自编码器+条件扩散变换器），将带限RIR上采样至全频带质量（48 kHz）",
      "首创基于矫正流匹配的自然语言描述生成RIR，支持多模态输入",
      "在RT60误差指标上显著优于基线（8.8% vs -37%），实现更真实的房间声学参数"
    ]
  },
  "Multi-Scale Alignment For CIF-Based Non-Autoregressive ASR": {
    "主题": "非自回归语音识别的多尺度对齐",
    "场景": "提升Continuous Integrate-and-Fire (CIF)机制在多语种（如英语、法语）语音识别中的稳定性和准确性",
    "创新点": [
      "提出多尺度CIF（M-CIF），通过逐步蒸馏字符和音素级监督到子词表示中，实现多级对齐",
      "引入音素混淆错误（PE）和空间相关分割错误（SE）作为新评估指标，定量分析多级对齐效果"
    ]
  },
  "Low-bitrate Neural Codec for First Order Ambisonics with   Spatial Consistency Loss": {
    "主题": "低比特率神经空间音频编解码器",
    "场景": "一阶Ambisonics (FOA) 空间音频的低比特率压缩与重建",
    "创新点": [
      "首次提出针对四通道FOA信号的离散神经空间音频编解码器，扩展WavTokenizer架构支持多通道输入",
      "引入新颖的空间一致性损失函数，在高度压缩表示下有效保留重建信号中的方向性线索",
      "编解码器可在0.9kbps极低比特率下工作（每秒75个离散令牌），并验证其在下游空间音频任务（如基于STARSS23实录音响的事件定位）中的特征有效性"
    ]
  },
  "Free-form Audio Editing using Natural Language   Instructions": {
    "主题": "音频自然语言编辑",
    "场景": "使用自由形式的自然语言指令编辑现有音频",
    "创新点": [
      "提出基于Stable Audio Open的SAO-Instruct模型，支持任意自然语言指令编辑音频，突破预定义指令限制",
      "构建包含输入音频-编辑指令-输出音频的三元组数据集，结合Prompt-to-Prompt、DDPM反演与人工编辑管道合成训练数据",
      "模型在合成数据上训练后能泛化至真实场景音频和未见过的编辑指令，主客观评估均优于现有方法"
    ]
  },
  "Streaming Generation for Music Accompaniment": {
    "主题": "实时音乐伴奏生成",
    "场景": "在实时音频输入（如歌手演唱）时同步生成连贯的伴奏（如吉他伴奏）",
    "创新点": [
      "提出考虑实际部署中系统延迟的模型设计，引入未来可见度（$t_f$）和输出块持续时间（$k$）两个变量优化实时性能",
      "发现$t_f$与$k$的权衡关系：增加$t_f$可提升连贯性但需要更快推理，增加$k$提高吞吐量但降低更新率导致质量下降",
      "揭示朴素最大似然训练在缺乏未来上下文时的局限性，提出需采用前瞻性和主动性目标改进实时即兴伴奏"
    ]
  },
  "Mitigating Attention Sinks and Massive Activations in Audio-Visual   Speech Recognition with LLMS": {
    "主题": "音频-视觉语音识别中的注意力机制优化",
    "场景": "在大语言模型（LLMs）驱动的多模态语音识别（ASR/VSR/AVSR）中，抑制注意力偏移和异常激活现象",
    "创新点": [
      "首次在多模态语音识别中发现并分析了注意力偏移（非BOS令牌的低语义中间令牌同样引发异常高注意力）与大规模激活（MLP层固定特征索引主导）现象",
      "提出基于解相关的损失函数，通过降低BOS令牌与中间令牌的余弦相似性，有效减少注意力偏移和异常激活",
      "方法在高特征降采样条件下提升识别准确率（WER），同时保持低降采样率时的稳定性"
    ]
  },
  "Towards Realistic Long-form Podcasts with Dialectal and   Paralinguistic Diversity": {
    "主题": "多语言方言的对话式文本转语音（TTS）系统",
    "场景": "多说话人、多轮对话的播客风格语音生成",
    "创新点": [
      "支持多语言（普通话、英语）及多种中国方言（四川话、河南话、粤语等），增强个性化播客语音生成",
      "集成副语言控制技术，实现对话中适应上下文的话调韵律变化",
      "可稳定生成超90分钟长对话，保持音色一致与平滑说话人切换"
    ]
  },
  "Benchmarking Instruction Sensitivity for Large Audio Language   Models": {
    "主题": "大型音频语言模型的指令敏感性评估",
    "场景": "评估和改进大型音频语言模型（LALMs）对不同指令表述的敏感性和任务执行能力。",
    "创新点": [
      "提出ISA-Bench基准，首次系统评估LALMs在指令描述、输出格式和任务组合三个维度上的敏感性。",
      "通过构建复杂指令变体数据集微调Qwen2-Audio，显著提升了模型对多样化指令的遵循能力。",
      "揭示了模型在适应新指令风格时出现的灾难性遗忘问题，为指令鲁棒性改进提供关键洞见。"
    ]
  },
  "Simulating Conversations from Read Literature for ASR and   Diarization": {
    "主题": "多说话人语音处理数据集",
    "场景": "用于语音识别（ASR）和说话人日志（Diarization）系统的训练与评估",
    "创新点": [
      "提出基于语义和时序连贯性的对话模拟方法（SASC），解决现有数据集语义割裂和时序失真问题",
      "设计新颖的房间脉冲响应选择流程，通过空间合理性排名优化声学真实性",
      "采用按书籍组织语料的结构，确保对话上下文一致性"
    ]
  },
  "Learning Linearity in Audio Consistency Autoencoders via Implicit   Regularization": {
    "主题": "线性音频自编码器",
    "场景": "音频处理中的压缩表示与代数操作",
    "创新点": [
      "提出通过数据增强实现隐式正则化，诱导高压缩一致性自编码器（CAE）的线性特性（增益等变和加法保持）",
      "在不改变模型架构或损失函数的前提下，实现编解码器的线性行为并保持重建保真度",
      "验证了通过简单潜在运算进行音乐源合成/分离的实用性"
    ]
  },
  "2025 Challenge Description": {
    "主题": "低资源音频编解码",
    "场景": "边缘计算环境下，要求低延迟、低比特率且抗声学失真（如背景噪声和混响）的音频编解码。",
    "创新点": [
      "提出结合神经编解码与增强技术的混合架构，优化低资源场景下的鲁棒性。",
      "设立标准化挑战框架（含数据集、基线系统、评估指标），推动编解码与下游音频任务的协同进步。"
    ]
  },
  "Arabic Children Speech Recognition Dataset": {
    "主题": "阿拉伯语儿童语音识别数据集",
    "场景": "低资源语言（阿拉伯语）环境下儿童语音识别，尤其在课堂环境中收集的儿童语音数据。",
    "创新点": [
      "提出首个针对阿拉伯语儿童语音的公开数据集（Arabic Little STT），填补了阿拉伯语儿童语音数据的空白。",
      "系统性评估Whisper模型在儿童语音识别上的性能，揭示其与成人语音识别的显著差距（WER从0.2升至0.66）。",
      "强调儿童语音数据需遵循严格的伦理与隐私保护框架，推动包容性ASR技术发展。"
    ]
  },
  "Benchmarking Audio Deepfake Detection across Synthesizer and   Speaker Shifts": {
    "主题": "音频深度伪造检测",
    "场景": "评估音频深度伪造检测器在未见过的合成方法和说话人条件下的鲁棒性",
    "创新点": [
      "提出TWINSHIFT基准，专门用于严格未见条件下（合成方法+说话人双重变化）的检测鲁棒性评估",
      "基于六种合成系统+不相交说话人集构建，首次实现生成模型与说话人身份同时迁移的针对性测试",
      "通过实验揭示现有系统的关键鲁棒性缺陷，为音频伪造检测系统开发提供原则性指导"
    ]
  }
}